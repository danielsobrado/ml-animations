---
title: "About ML Animations"
---

This blog accompanies the [ML Animations](https://danielsobrado.github.io/ml-animations/) project - a collection of interactive visualizations explaining machine learning concepts.

## What you'll find here

Each article explains a concept from the animations in more depth:

- **Transformers & Attention**: How modern language models work
- **NLP Fundamentals**: Word2Vec, embeddings, tokenization
- **Neural Networks**: Activations, normalization, architectures
- **Math Foundations**: Linear algebra, probability, optimization
- **Reinforcement Learning**: Q-learning, exploration, MDPs
- **Algorithms**: PageRank, Bloom filters

## Why visualizations?

ML concepts click better when you see them. A picture of gradient descent navigating a loss surface beats equations. Watching attention weights form makes transformers less magical.

The animations are interactive - play with parameters, see what changes.

## About the writing

These articles try to explain things like a colleague would over coffee. Not academic papers. Occasional shortcuts and simplifications where they help understanding.

If something's unclear or wrong, open an issue.

## Links

- [Interactive Animations](https://danielsobrado.github.io/ml-animations/)
- [GitHub Repository](https://github.com/danielsobrado/ml-animations)
