import{r as c,j as e,w as N}from"./index-CsxpOLHd.js";import{T as y}from"./trophy-Dwhtv2pZ.js";import{R as V}from"./rotate-ccw-xVnQluc9.js";import{C as u}from"./check-circle-C5pajHEW.js";import{X as p}from"./x-circle-guWBBJ3U.js";import{H as G}from"./help-circle-B0uJ_rS0.js";function P(){const[o,x]=c.useState(0),[n,d]=c.useState(null),[r,m]=c.useState(!1),[l,h]=c.useState(0),[a,g]=c.useState([]),t=[{question:"What does GloVe stand for?",options:["Global Vectors for Word Representation","Graphical Language Output Vector Encoding","Generalized Linear Output Vectors","Global Language Vector Embeddings"],correct:0,explanation:"GloVe stands for Global Vectors for Word Representation. It emphasizes the use of global word-word co-occurrence statistics."},{question:"What is the co-occurrence matrix X in GloVe?",options:["A matrix where X_ij is the count of word j appearing in context of word i","A matrix of word similarities","A matrix of TF-IDF scores","A matrix of one-hot encoded words"],correct:0,explanation:"The co-occurrence matrix X_ij counts how many times word j appears within a context window of word i across the entire corpus."},{question:"Why does GloVe use a weighting function f(X_ij)?",options:["To speed up training","To prevent frequent word pairs from dominating the objective","To normalize the embeddings","To handle out-of-vocabulary words"],correct:1,explanation:'The weighting function f(X_ij) prevents very common word pairs (like "the, of") from dominating the loss. It caps at x_max and uses α=0.75 for smoothing.'},{question:"What is the key insight behind GloVe's objective function?",options:["Word similarity is based on word length","Probability ratios encode semantic relationships","Words should have orthogonal vectors","Frequent words are more important"],correct:1,explanation:`GloVe's key insight is that the ratio P(k|ice)/P(k|steam) reveals whether word k is more related to "ice" or "steam", capturing semantic relationships.`},{question:"How does GloVe differ from Word2Vec in training approach?",options:["GloVe uses neural networks, Word2Vec uses matrix factorization","GloVe pre-computes global statistics, Word2Vec uses local windows online","GloVe is faster to train","GloVe requires labeled data"],correct:1,explanation:"GloVe pre-computes a co-occurrence matrix from the entire corpus before training, while Word2Vec trains incrementally using local context windows and SGD."},{question:"What is the typical value of x_max in the weighting function?",options:["10","50","100","1000"],correct:2,explanation:"The authors recommend x_max = 100, meaning co-occurrences above 100 are capped at weight 1.0 to prevent very common pairs from dominating."},{question:"What is the final word embedding in GloVe?",options:["Just the word vector W","Just the context vector W̃","W + W̃ (sum of both)","W × W̃ (product of both)"],correct:2,explanation:"Since W and W̃ are symmetric in GloVe's objective, the final embedding is W + W̃, which gives slightly better performance than using either alone."},{question:"Which organization released GloVe?",options:["Google","Stanford NLP Group","Facebook AI","OpenAI"],correct:1,explanation:"GloVe was released by the Stanford NLP Group in 2014, authored by Jeffrey Pennington, Richard Socher, and Christopher Manning."},{question:"What does the α parameter (typically 0.75) control?",options:["Learning rate","Embedding dimension","Smoothing of the weighting function","Context window size"],correct:2,explanation:"α = 0.75 is the power in f(x) = (x/x_max)^α, which smooths the weighting so that rare co-occurrences still contribute meaningfully."},{question:"Which statement about GloVe is TRUE?",options:["GloVe can be trained incrementally on new data","GloVe uses negative sampling like Word2Vec","GloVe training only considers non-zero co-occurrence entries","GloVe produces sparse word vectors"],correct:2,explanation:"GloVe only trains on observed (non-zero) co-occurrences. Unlike Word2Vec's negative sampling, GloVe uses weighted least squares on the sparse matrix."}],b=i=>{if(r)return;d(i),m(!0);const s=i===t[o].correct;s&&h(v=>v+1),g([...a,{question:o,correct:s}])},f=()=>{o<t.length-1&&(x(i=>i+1),d(null),m(!1))},j=()=>{x(0),d(null),m(!1),h(0),g([])},w=a.length===t.length;return e.jsxs("div",{className:"space-y-6 pb-20",children:[e.jsxs("div",{className:"text-center",children:[e.jsxs("h2",{className:"text-3xl font-bold mb-2",children:[e.jsx("span",{className:"gradient-text",children:"Practice"})," Quiz"]}),e.jsx("p",{className:"text-gray-400",children:"Test your understanding of GloVe"})]}),e.jsxs("div",{className:"bg-black/30 rounded-xl p-4 border border-white/10",children:[e.jsxs("div",{className:"flex justify-between items-center mb-2",children:[e.jsx("span",{className:"text-sm text-gray-400",children:"Progress"}),e.jsxs("span",{className:"text-sm text-violet-400",children:[a.length," / ",t.length]})]}),e.jsx("div",{className:"flex gap-1",children:t.map((i,s)=>e.jsx("div",{className:`h-2 flex-1 rounded-full transition-all ${a[s]!==void 0?a[s].correct?"bg-green-500":"bg-red-500":s===o?"bg-violet-500":"bg-white/10"}`},s))}),e.jsxs("div",{className:"flex justify-between items-center mt-2",children:[e.jsx("span",{className:"text-sm text-gray-400",children:"Score"}),e.jsxs("span",{className:"text-sm text-green-400",children:[l," correct"]})]})]}),w?e.jsxs("div",{className:"bg-gradient-to-r from-violet-900/30 to-cyan-900/30 rounded-2xl p-8 border border-violet-500/30 text-center",children:[e.jsx(y,{size:64,className:"mx-auto text-yellow-400 mb-4"}),e.jsx("h3",{className:"text-2xl font-bold text-white mb-2",children:"Quiz Complete!"}),e.jsxs("p",{className:"text-4xl font-bold text-violet-400 mb-4",children:[l," / ",t.length]}),e.jsx("p",{className:"text-gray-400 mb-6",children:l===t.length?"Perfect score! You've mastered GloVe!":l>=t.length*.7?"Great job! You have a solid understanding of GloVe.":"Keep practicing! Review the concepts and try again."}),e.jsxs("button",{onClick:j,className:"flex items-center gap-2 mx-auto px-6 py-3 bg-violet-600 hover:bg-violet-700 rounded-lg transition-colors",children:[e.jsx(V,{size:18}),"Try Again"]})]}):e.jsxs(e.Fragment,{children:[e.jsxs("div",{className:"bg-black/30 rounded-2xl p-6 border border-white/10",children:[e.jsx("div",{className:"flex items-center gap-2 mb-4",children:e.jsxs("span",{className:"px-3 py-1 bg-violet-600 rounded-full text-sm",children:["Question ",o+1]})}),e.jsx("h3",{className:"text-xl font-medium text-white mb-6",children:t[o].question}),e.jsx("div",{className:"grid gap-3",children:t[o].options.map((i,s)=>e.jsx("button",{onClick:()=>b(s),disabled:r,className:`p-4 rounded-lg text-left transition-all border ${r?s===t[o].correct?"bg-green-900/30 border-green-500 text-green-400":s===n?"bg-red-900/30 border-red-500 text-red-400":"bg-white/5 border-white/10 text-gray-500":"bg-white/5 border-white/10 hover:bg-white/10 hover:border-white/20 text-white"}`,children:e.jsxs("div",{className:"flex items-center gap-3",children:[e.jsx("span",{className:`w-8 h-8 rounded-full flex items-center justify-center text-sm font-medium ${r?s===t[o].correct?"bg-green-500 text-black":s===n?"bg-red-500 text-white":"bg-white/10":"bg-white/10"}`,children:r&&s===t[o].correct?e.jsx(u,{size:18}):r&&s===n?e.jsx(p,{size:18}):String.fromCharCode(65+s)}),e.jsx("span",{children:i})]})},s))})]}),r&&e.jsx("div",{className:`rounded-xl p-4 border ${n===t[o].correct?"bg-green-900/20 border-green-500/30":"bg-red-900/20 border-red-500/30"}`,children:e.jsxs("div",{className:"flex items-start gap-3",children:[n===t[o].correct?e.jsx(u,{className:"text-green-400 mt-1 flex-shrink-0",size:20}):e.jsx(p,{className:"text-red-400 mt-1 flex-shrink-0",size:20}),e.jsxs("div",{children:[e.jsx("p",{className:`font-medium ${n===t[o].correct?"text-green-400":"text-red-400"}`,children:n===t[o].correct?"Correct!":"Not quite right"}),e.jsx("p",{className:"text-gray-300 mt-1 text-sm",children:t[o].explanation})]})]})}),r&&o<t.length-1&&e.jsx("div",{className:"flex justify-center",children:e.jsxs("button",{onClick:f,className:"flex items-center gap-2 px-6 py-3 bg-violet-600 hover:bg-violet-700 rounded-lg transition-colors",children:["Next Question",e.jsx(N,{size:18})]})})]}),e.jsxs("div",{className:"bg-gradient-to-r from-violet-900/20 to-cyan-900/20 rounded-xl p-6 border border-violet-500/30",children:[e.jsxs("h4",{className:"flex items-center gap-2 font-bold text-violet-400 mb-4",children:[e.jsx(G,{size:18}),"Quick Reference"]}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4 text-sm",children:[e.jsxs("div",{className:"bg-black/30 rounded-lg p-3",children:[e.jsx("p",{className:"text-violet-400 font-medium mb-1",children:"GloVe Objective"}),e.jsx("p",{className:"text-gray-400 font-mono text-xs",children:"J = Σ f(X)(w·w̃ + b - log X)²"})]}),e.jsxs("div",{className:"bg-black/30 rounded-lg p-3",children:[e.jsx("p",{className:"text-cyan-400 font-medium mb-1",children:"Weighting Function"}),e.jsx("p",{className:"text-gray-400 font-mono text-xs",children:"f(x) = (x/x_max)^0.75 if x < 100"})]}),e.jsxs("div",{className:"bg-black/30 rounded-lg p-3",children:[e.jsx("p",{className:"text-green-400 font-medium mb-1",children:"Final Embedding"}),e.jsx("p",{className:"text-gray-400",children:"W + W̃ (word + context)"})]}),e.jsxs("div",{className:"bg-black/30 rounded-lg p-3",children:[e.jsx("p",{className:"text-yellow-400 font-medium mb-1",children:"Key Insight"}),e.jsx("p",{className:"text-gray-400",children:"P(k|i) / P(k|j) encodes meaning"})]})]})]})]})}export{P as default};
