import{r as l,j as e,u as V,h as Y,i as D,k}from"./index-CsxpOLHd.js";import{S as q,C as M,O,W as H,P as U,M as _,a as B,E as X,L as J,b as K,G as Z,c as ee,B as se,d as te}from"./three.module-CNl0Zq82.js";const A=[{id:1,title:"Tokenization & Embeddings",path:"/step1",description:"How text becomes numbers",component:"Step1Tokenization"},{id:2,title:"Positional Encoding",path:"/step2",description:"Adding position information",component:"Step2Positional"},{id:3,title:"Multi-Head Attention",path:"/step3",description:"The core of transformers",component:"Step3Attention"},{id:4,title:"Feed-Forward Network",path:"/step4",description:"Processing each position",component:"Step4FFN"},{id:5,title:"Layer Norm & Residuals",path:"/step5",description:"Stable training",component:"Step5Norm"},{id:6,title:"Full Architecture",path:"/step6",description:"Putting it all together",component:"Step6Architecture"},{id:7,title:"Weight Tying",path:"/step7",description:"Optimization: Parameter sharing",component:"Step7WeightTying"},{id:8,title:"Training Optimizations",path:"/step8",description:"Making training efficient",component:"Step8Training"},{id:9,title:"Inference Optimizations",path:"/step9",description:"Fast generation",component:"Step9Inference"}];function R({onComplete:h,onNext:g}){const[m,r]=l.useState("Hello, GPT-2!"),[d,a]=l.useState([]),[i,o]=l.useState(""),[c,s]=l.useState(""),x=t=>{const n=t.split(/(\s+|[,.!?])/g).filter(b=>b.trim());a(n)},u=()=>{const t=i.toLowerCase().includes("subword");s(t?"âœ“ Correct! BPE breaks text into subword units, allowing the model to handle unknown words.":"âœ— Try again. Think about how BPE handles rare or unknown words."),t&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 1: Tokenization & Embeddings"}),e.jsx("p",{className:"text-gray-400",children:"How text becomes numbers that GPT-2 can understand"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"What is Tokenization?"}),e.jsxs("p",{className:"text-gray-300",children:["GPT-2 can't process raw text - it needs numbers. ",e.jsx("strong",{children:"Tokenization"})," converts text into a sequence of tokens (subword units)."]}),e.jsxs("p",{className:"text-gray-300",children:["GPT-2 uses ",e.jsx("strong",{children:"Byte-Pair Encoding (BPE)"})," with a vocabulary of 50,257 tokens. This allows it to:"]}),e.jsxs("ul",{className:"list-disc list-inside space-y-1 text-gray-300 ml-4",children:[e.jsx("li",{children:"Handle any text (including rare words)"}),e.jsx("li",{children:"Break unknown words into known subwords"}),e.jsx("li",{children:"Keep common words as single tokens"})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Try it Yourself"}),e.jsxs("div",{children:[e.jsx("label",{className:"block text-sm text-gray-400 mb-2",children:"Enter text:"}),e.jsx("input",{type:"text",value:m,onChange:t=>r(t.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-emerald-500 focus:outline-none",placeholder:"Type anything..."})]}),e.jsx("button",{onClick:()=>x(m),className:"px-6 py-2 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Tokenize"}),d.length>0&&e.jsxs("div",{className:"mt-4",children:[e.jsxs("div",{className:"text-sm text-gray-400 mb-2",children:["Tokens (",d.length,"):"]}),e.jsx("div",{className:"flex flex-wrap gap-2",children:d.map((t,n)=>e.jsx("div",{className:"bg-emerald-900 text-emerald-100 px-3 py-1 rounded text-sm font-mono",children:t},n))})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Token Embeddings"}),e.jsxs("p",{className:"text-gray-300",children:["Each token is converted to a ",e.jsx("strong",{children:"learned embedding vector"})," of size 768 (for GPT-2 Small)."]}),e.jsx("div",{className:"bg-gray-900 p-4 rounded font-mono text-sm text-gray-300",children:'Token "Hello" â†’ Token ID: 15496 â†’ Embedding: [0.23, -0.45, 0.12, ..., 0.67] (768 dimensions)'}),e.jsxs("p",{className:"text-gray-300",children:["These embeddings are ",e.jsx("strong",{children:"learned during training"})," so that similar tokens have similar vectors."]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"Why does GPT-2 use Byte-Pair Encoding instead of word-level tokenization?"}),e.jsx("textarea",{value:i,onChange:t=>o(t.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:u,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),c&&e.jsx("div",{className:`p-3 rounded ${c.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:c})]}),e.jsx("div",{className:"flex justify-end",children:e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Positional Encoding â†’"})})]})}function re({onComplete:h,onNext:g,onPrev:m}){const r=l.useRef(null),[d,a]=l.useState(0),[i,o]=l.useState(""),[c,s]=l.useState(""),x=768;l.useEffect(()=>{const t=r.current;if(!t)return;const n=t.getContext("2d"),b=t.width,j=t.height;n.fillStyle="#1f2937",n.fillRect(0,0,b,j);const w=50,f=b/w,C=30;for(let p=0;p<w;p++){const S=p*f,z=p===d,y=p/w*360;n.fillStyle=z?`hsl(${y}, 100%, 60%)`:`hsl(${y}, 70%, 40%)`,n.fillRect(S,50,f-1,C),z&&(n.strokeStyle="#10b981",n.lineWidth=3,n.strokeRect(S,50,f-1,C))}n.fillStyle="#9ca3af",n.font="12px monospace",n.fillText("Position 0",5,40),n.fillText(`Position ${w-1}`,b-80,40),n.fillText("Each position gets a unique learned vector",5,j-10)},[d]);const u=()=>{const t=i.toLowerCase().includes("order")||i.toLowerCase().includes("position");s(t?'âœ“ Correct! Without positional encodings, the model would treat "dog bites man" the same as "man bites dog".':"âœ— Try again. Think about what information is lost without position encodings."),t&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 2: Positional Encoding"}),e.jsx("p",{className:"text-gray-400",children:"Teaching the model about word order"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Why Positional Encoding?"}),e.jsxs("p",{className:"text-gray-300",children:["Self-attention is ",e.jsx("strong",{children:"permutation-invariant"}),' - it treats sequences as unordered sets. But word order matters! "Dog bites man" â‰  "Man bites dog"']}),e.jsxs("p",{className:"text-gray-300",children:["GPT-2 uses ",e.jsx("strong",{children:"learned absolute positional embeddings"}),":"]}),e.jsxs("ul",{className:"list-disc list-inside space-y-1 text-gray-300 ml-4",children:[e.jsx("li",{children:"Each position (0 to 1023) has its own learned embedding vector"}),e.jsxs("li",{children:["These are ",e.jsx("strong",{children:"added"})," to the token embeddings"]}),e.jsx("li",{children:"Allows the model to learn position-dependent patterns"})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Positional Embedding Visualization"}),e.jsx("canvas",{ref:r,width:600,height:120,className:"border border-gray-700 rounded cursor-pointer",onClick:t=>{const n=t.target.getBoundingClientRect(),b=t.clientX-n.left,j=Math.floor(b/n.width*50);a(Math.max(0,Math.min(49,j)))}}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded",children:[e.jsxs("div",{className:"text-sm text-gray-400",children:["Selected Position: ",e.jsx("span",{className:"text-emerald-400 font-mono",children:d})]}),e.jsxs("div",{className:"text-sm text-gray-400",children:["Embedding Dimension: ",e.jsx("span",{className:"text-emerald-400 font-mono",children:x})]})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"How It Works"}),e.jsx("div",{className:"bg-gray-900 p-4 rounded space-y-2",children:e.jsxs("div",{className:"font-mono text-sm text-gray-300",children:[e.jsxs("div",{children:["Token Embedding: ",e.jsx("span",{className:"text-blue-400",children:"E_token"})," (768-dim)"]}),e.jsxs("div",{children:["Position Embedding: ",e.jsx("span",{className:"text-yellow-400",children:"E_pos"})," (768-dim)"]}),e.jsx("div",{className:"mt-2 text-emerald-400",children:"Final Input: E_token + E_pos"})]})}),e.jsxs("p",{className:"text-gray-300 text-sm",children:[e.jsx("strong",{children:"Alternative:"})," Original Transformer used sinusoidal encodings (not learned). GPT-2 learns them because it can capture more complex position-dependent patterns."]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"What would happen if we removed positional encodings from GPT-2?"}),e.jsx("textarea",{value:i,onChange:t=>o(t.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:u,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),c&&e.jsx("div",{className:`p-3 rounded ${c.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:c})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Multi-Head Attention â†’"})]})]})}function ne({onComplete:h,onNext:g,onPrev:m}){const r=l.useRef(null),d=l.useRef(null),[a]=l.useState(12),[i,o]=l.useState(!0),[c,s]=l.useState(""),[x,u]=l.useState("");l.useEffect(()=>{if(!r.current)return;const n=400,b=400,j=new q;j.background=new M(2042167),d.current=j;const w=new O(n/-2,n/2,b/2,b/-2,.1,1e3);w.position.z=100;const f=new H({antialias:!0});f.setSize(n,b),r.current.appendChild(f.domElement);const C=5,p=60,S=5,z=-325/2+p/2,y=C*(p+S)/2-p/2;for(let v=0;v<C;v++)for(let N=0;N<C;N++){const T=i&&N>v,W=new U(p,p),L=T?0:1-Math.abs(v-N)/C,G=T?new M(3621201):new M().setHSL(.55,.7,.3+L*.4),Q=new _({color:G}),E=new B(W,Q);E.position.x=z+N*(p+S),E.position.y=y-v*(p+S),j.add(E);const $=new X(W),I=new J($,new K({color:4937059}));I.position.copy(E.position),j.add(I)}let P;const F=()=>{P=requestAnimationFrame(F),f.render(j,w)};return F(),()=>{var v;cancelAnimationFrame(P),f.dispose(),(v=r.current)!=null&&v.contains(f.domElement)&&r.current.removeChild(f.domElement)}},[i]);const t=()=>{const n=c.toLowerCase().includes("future")||c.toLowerCase().includes("next");u(n?'âœ“ Correct! Causal masking prevents the model from "cheating" by looking at future tokens during training.':"âœ— Try again. Think about what would happen if the model could see future tokens when predicting the next word."),n&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 3: Multi-Head Self-Attention"}),e.jsx("p",{className:"text-gray-400",children:"The core mechanism that makes transformers powerful"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"What is Self-Attention?"}),e.jsxs("p",{className:"text-gray-300",children:["Self-attention allows each token to ",e.jsx("strong",{children:"look at all other tokens"}),' in the sequence and decide how much to "pay attention" to each one.']}),e.jsx("p",{className:"text-gray-300",children:"For each token, we compute:"}),e.jsxs("ul",{className:"list-disc list-inside space-y-1 text-gray-300 ml-4",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Query (Q)"}),": What am I looking for?"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Key (K)"}),": What do I contain?"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Value (V)"}),": What information do I have?"]})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"The Math"}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded space-y-2 font-mono text-sm",children:[e.jsxs("div",{className:"text-gray-300",children:["Attention(Q, K, V) = softmax(QK",e.jsx("sup",{children:"T"})," / âˆšd",e.jsx("sub",{children:"k"}),") V"]}),e.jsxs("div",{className:"text-gray-400 text-xs mt-2",children:["where d",e.jsx("sub",{children:"k"})," = 64 (dimension per head)"]})]}),e.jsxs("p",{className:"text-gray-300 text-sm",children:["Steps: (1) Compute attention scores (QK",e.jsx("sup",{children:"T"}),"), (2) Scale by âˆšd",e.jsx("sub",{children:"k"}),", (3) Apply softmax, (4) Multiply by values (V)"]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Attention Pattern (Simplified 5Ã—5)"}),e.jsxs("div",{className:"flex flex-col items-center gap-4",children:[e.jsx("div",{ref:r,className:"border border-gray-700 rounded"}),e.jsx("div",{className:"flex items-center gap-4",children:e.jsxs("label",{className:"flex items-center gap-2 text-gray-300",children:[e.jsx("input",{type:"checkbox",checked:i,onChange:n=>o(n.target.checked),className:"w-4 h-4"}),"Show Causal Mask"]})}),e.jsxs("div",{className:"text-sm text-gray-400 text-center",children:["Rows = Query positions, Columns = Key positions",e.jsx("br",{}),"Brighter = Higher attention weight"]})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Multi-Head Attention"}),e.jsxs("p",{className:"text-gray-300",children:["GPT-2 uses ",e.jsxs("strong",{children:[a," parallel attention heads"]}),". Each head:"]}),e.jsxs("ul",{className:"list-disc list-inside space-y-1 text-gray-300 ml-4",children:[e.jsx("li",{children:"Has its own Q, K, V weight matrices"}),e.jsx("li",{children:"Learns different aspects (e.g., syntax, semantics, position)"}),e.jsx("li",{children:"Outputs are concatenated and projected"})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded",children:[e.jsxs("div",{className:"text-sm text-gray-400",children:["Dimension per head: ",e.jsx("span",{className:"text-emerald-400",children:"64"})," (768 / 12)"]}),e.jsxs("div",{className:"text-sm text-gray-400",children:["Total output: ",e.jsx("span",{className:"text-emerald-400",children:"768"})]})]})]}),e.jsxs("div",{className:"bg-yellow-900 bg-opacity-30 border border-yellow-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-yellow-400",children:"âš ï¸ Causal Masking"}),e.jsxs("p",{className:"text-gray-300",children:["GPT-2 is a ",e.jsx("strong",{children:"decoder-only"})," model. During training, we prevent it from looking at future tokens by applying a ",e.jsx("strong",{children:"causal mask"})," (upper triangle = -âˆž before softmax)."]}),e.jsx("p",{className:"text-gray-300 text-sm",children:"This ensures the model learns to predict the next token using only past context, mimicking real autoregressive generation."})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"Why does GPT-2 use causal masking? What would happen without it?"}),e.jsx("textarea",{value:c,onChange:n=>s(n.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:t,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),x&&e.jsx("div",{className:`p-3 rounded ${x.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:x})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("div",{className:"text-gray-400 flex items-center",children:"Steps 4-9 coming soon!"})]})]})}function ae({onComplete:h,onNext:g,onPrev:m}){const r=l.useRef(null),[d,a]=l.useState(""),[i,o]=l.useState("");l.useEffect(()=>{if(!r.current)return;const s=600,x=300,u=new q;u.background=new M(2042167);const t=new O(s/-2,s/2,x/2,x/-2,.1,1e3);t.position.z=100;const n=new H({antialias:!0});n.setSize(s,x),r.current.appendChild(n.domElement);const b=(y,P,F,v)=>{const N=new Z,T=25,W=y*T/2-T/2;for(let L=0;L<y;L++){const G=new ee(6,32),Q=new _({color:F}),E=new B(G,Q);E.position.y=W-L*T,N.add(E)}return N.position.x=P,u.add(N),N},j=b(8,-200,6003669),w=b(32,0,16760832),f=b(8,200,7384391),C=new K({color:16777215,transparent:!0,opacity:.1}),p=(y,P)=>{y.children.forEach(F=>{P.children.forEach(v=>{const N=[F.position.clone().add(y.position),v.position.clone().add(P.position)],T=new se().setFromPoints(N),W=new te(T,C);u.add(W)})})};p(j,w),p(w,f);let S;const z=()=>{S=requestAnimationFrame(z),n.render(u,t)};return z(),()=>{var y;cancelAnimationFrame(S),n.dispose(),(y=r.current)!=null&&y.contains(n.domElement)&&r.current.removeChild(n.domElement)}},[]);const c=()=>{const s=d.toLowerCase().includes("4")||d.toLowerCase().includes("four");o(s?"âœ“ Correct! The internal dimension is typically 4 times the embedding dimension.":"âœ— Try again. How much larger is the hidden layer compared to the input?"),s&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 4: Feed-Forward Network"}),e.jsx("p",{className:"text-gray-400",children:"Processing information position-wise"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:'The "Brain" of the Block'}),e.jsxs("p",{className:"text-gray-300",children:["After attention gathers information from other tokens, the ",e.jsx("strong",{children:"Feed-Forward Network (FFN)"})," processes each token ",e.jsx("em",{children:"independently"}),"."]}),e.jsx("p",{className:"text-gray-300",children:"It consists of two linear transformations with a non-linear activation function in between."})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Expansion & Contraction"}),e.jsx("div",{ref:r,className:"border border-gray-700 rounded flex justify-center overflow-hidden"}),e.jsxs("div",{className:"flex justify-between text-sm text-gray-400 px-10",children:[e.jsx("span",{children:"Input (d_model)"}),e.jsx("span",{children:"Hidden (4 Ã— d_model)"}),e.jsx("span",{children:"Output (d_model)"})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"The Math"}),e.jsx("div",{className:"bg-gray-900 p-4 rounded space-y-2 font-mono text-sm",children:e.jsxs("div",{className:"text-gray-300",children:["FFN(x) = GELU(xW",e.jsx("sub",{children:"1"})," + b",e.jsx("sub",{children:"1"}),")W",e.jsx("sub",{children:"2"})," + b",e.jsx("sub",{children:"2"})]})}),e.jsxs("ul",{className:"list-disc list-inside space-y-1 text-gray-300 ml-4",children:[e.jsxs("li",{children:[e.jsx("strong",{children:"Expansion"}),": Project from 768 to 3072 dimensions"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Activation"}),": Apply GELU (Gaussian Error Linear Unit)"]}),e.jsxs("li",{children:[e.jsx("strong",{children:"Contraction"}),": Project back to 768 dimensions"]})]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"If the embedding dimension (d_model) is 768, what is the dimension of the hidden layer in the FFN?"}),e.jsx("input",{type:"text",value:d,onChange:s=>a(s.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none",placeholder:"Enter a number..."}),e.jsx("button",{onClick:c,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),i&&e.jsx("div",{className:`p-3 rounded ${i.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:i})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Layer Norm & Residuals â†’"})]})]})}function ie({onComplete:h,onNext:g,onPrev:m}){const[r,d]=l.useState(""),[a,i]=l.useState(""),o=()=>{const c=r.toLowerCase().includes("gradient")||r.toLowerCase().includes("vanish");i(c?"âœ“ Correct! Residual connections provide a direct path for gradients to flow backward, solving the vanishing gradient problem.":"âœ— Try again. What major problem in deep networks do skip connections solve?"),c&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 5: Layer Norm & Residuals"}),e.jsx("p",{className:"text-gray-400",children:"The secret sauce for training deep networks"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Residual Connections (Skip Connections)"}),e.jsx("p",{className:"text-gray-300",children:"Deep networks are hard to train because gradients vanish as they propagate back through many layers."}),e.jsxs("p",{className:"text-gray-300",children:[e.jsx("strong",{children:"Residual connections"})," solve this by adding the input of a layer to its output:"]}),e.jsx("div",{className:"bg-gray-900 p-4 rounded font-mono text-center text-emerald-400",children:"Output = Layer(Input) + Input"}),e.jsx("p",{className:"text-gray-300 text-sm",children:'This creates a "highway" for gradients to flow unchanged during backpropagation.'})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4 flex flex-col items-center",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Pre-Layer Normalization (GPT-2 Style)"}),e.jsxs("div",{className:"relative w-64 h-96 bg-gray-900 rounded-lg p-4 flex flex-col items-center justify-between border border-gray-700",children:[e.jsx("div",{className:"w-full text-center text-gray-400",children:"Input x"}),e.jsx("div",{className:"w-0.5 h-4 bg-gray-500"}),e.jsx("div",{className:"w-full h-0.5 bg-gray-500 relative",children:e.jsx("div",{className:"absolute -right-2 -top-1 text-xs text-gray-500",children:"Residual Path"})}),e.jsxs("div",{className:"flex w-full justify-between",children:[e.jsxs("div",{className:"flex flex-col items-center w-1/2 border-r border-gray-800 pr-2",children:[e.jsx("div",{className:"w-0.5 h-4 bg-gray-500"}),e.jsx("div",{className:"px-3 py-2 bg-purple-900 rounded border border-purple-700 text-xs text-center w-full",children:"Layer Norm"}),e.jsx("div",{className:"w-0.5 h-4 bg-gray-500"}),e.jsx("div",{className:"px-3 py-4 bg-blue-900 rounded border border-blue-700 text-xs text-center w-full font-bold",children:"Attention / FFN"}),e.jsx("div",{className:"w-0.5 h-4 bg-gray-500"})]}),e.jsx("div",{className:"w-1/2 h-full border-l-2 border-dashed border-gray-600 ml-2 relative"})]}),e.jsx("div",{className:"w-8 h-8 rounded-full bg-gray-700 flex items-center justify-center border border-gray-500 z-10 -mt-4",children:"+"}),e.jsx("div",{className:"w-0.5 h-4 bg-gray-500"}),e.jsx("div",{className:"w-full text-center text-gray-400",children:"Output"})]}),e.jsxs("p",{className:"text-sm text-gray-400 mt-2 text-center",children:["In GPT-2, Layer Norm is applied ",e.jsx("strong",{children:"before"})," the sub-layer (Pre-LN), unlike the original Transformer (Post-LN). This improves stability."]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"Why are residual connections critical for training deep networks like GPT-2 (which has up to 48 layers)?"}),e.jsx("textarea",{value:r,onChange:c=>d(c.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:o,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),a&&e.jsx("div",{className:`p-3 rounded ${a.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:a})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Full Architecture â†’"})]})]})}function le({onComplete:h,onNext:g,onPrev:m}){const[r,d]=l.useState("small"),[a,i]=l.useState(""),[o,c]=l.useState(""),s={small:{layers:12,heads:12,d_model:768,params:"124M"},medium:{layers:24,heads:16,d_model:1024,params:"355M"},large:{layers:36,heads:20,d_model:1280,params:"774M"},xl:{layers:48,heads:25,d_model:1600,params:"1.5B"}},x=s[r],u=()=>{const t=a.includes("124")||a.toLowerCase().includes("million");c(t?"âœ“ Correct! GPT-2 Small has approximately 124 million parameters.":"âœ— Try again. Look at the configuration table above for GPT-2 Small."),t&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 6: Full Architecture"}),e.jsx("p",{className:"text-gray-400",children:"Stacking it all together"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-6",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"GPT-2 Configurations"}),e.jsx("div",{className:"flex gap-4 mb-4",children:Object.keys(s).map(t=>e.jsx("button",{onClick:()=>d(t),className:`px-4 py-2 rounded font-bold capitalize transition-colors ${r===t?"bg-emerald-600 text-white":"bg-gray-700 text-gray-300 hover:bg-gray-600"}`,children:t},t))}),e.jsxs("div",{className:"grid grid-cols-2 md:grid-cols-4 gap-4",children:[e.jsxs("div",{className:"bg-gray-900 p-4 rounded text-center",children:[e.jsx("div",{className:"text-gray-400 text-sm",children:"Layers"}),e.jsx("div",{className:"text-2xl font-mono text-emerald-400",children:x.layers})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded text-center",children:[e.jsx("div",{className:"text-gray-400 text-sm",children:"Heads"}),e.jsx("div",{className:"text-2xl font-mono text-emerald-400",children:x.heads})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded text-center",children:[e.jsx("div",{className:"text-gray-400 text-sm",children:"Embedding Dim"}),e.jsx("div",{className:"text-2xl font-mono text-emerald-400",children:x.d_model})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded text-center",children:[e.jsx("div",{className:"text-gray-400 text-sm",children:"Parameters"}),e.jsx("div",{className:"text-2xl font-mono text-emerald-400",children:x.params})]})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4 flex flex-col items-center",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"The Stack"}),e.jsxs("div",{className:"w-64 border-2 border-gray-700 rounded-lg p-2 bg-gray-900",children:[e.jsx("div",{className:"h-10 bg-red-900/50 border border-red-700 rounded mb-2 flex items-center justify-center text-xs text-red-200",children:"Output Projection (Unembedding)"}),e.jsxs("div",{className:"space-y-1 mb-2 relative",children:[e.jsxs("div",{className:"h-12 bg-blue-900/50 border border-blue-700 rounded flex items-center justify-center text-xs text-blue-200",children:["Transformer Block ",x.layers]}),e.jsxs("div",{className:"h-8 flex items-center justify-center text-gray-500 text-xs",children:["... x ",x.layers-2," ..."]}),e.jsx("div",{className:"h-12 bg-blue-900/50 border border-blue-700 rounded flex items-center justify-center text-xs text-blue-200",children:"Transformer Block 1"}),e.jsx("div",{className:"absolute -left-8 top-0 bottom-0 w-4 border-l-2 border-gray-600 flex items-center",children:e.jsxs("span",{className:"text-xs text-gray-500 -rotate-90 whitespace-nowrap -ml-8",children:["Repeat ",x.layers,"x"]})})]}),e.jsx("div",{className:"h-10 bg-green-900/50 border border-green-700 rounded flex items-center justify-center text-xs text-green-200",children:"Token + Pos Embeddings"})]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"How many parameters does the GPT-2 Small model have?"}),e.jsx("input",{type:"text",value:a,onChange:t=>i(t.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none",placeholder:"e.g., 100M"}),e.jsx("button",{onClick:u,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),o&&e.jsx("div",{className:`p-3 rounded ${o.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:o})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Weight Tying â†’"})]})]})}function oe({onComplete:h,onNext:g,onPrev:m}){const[r,d]=l.useState(""),[a,i]=l.useState(""),s=50257*768/1e6,x=()=>{const u=r.toLowerCase().includes("memory")||r.toLowerCase().includes("parameter")||r.toLowerCase().includes("size");i(u?"âœ“ Correct! Weight tying significantly reduces the total number of parameters, saving memory and improving regularization.":"âœ— Try again. What is the main benefit of reusing the same matrix for two different parts of the model?"),u&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 7: Weight Tying"}),e.jsx("p",{className:"text-gray-400",children:"A clever trick to save parameters"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"What is Weight Tying?"}),e.jsxs("p",{className:"text-gray-300",children:["In GPT-2, the matrix used to convert tokens to embeddings (Input Embedding) is ",e.jsx("strong",{children:"the same matrix"})," used to convert the final output back to token probabilities (Unembedding / Output Projection)."]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded font-mono text-center text-emerald-400",children:["W",e.jsx("sub",{children:"input"})," = W",e.jsx("sub",{children:"output"}),e.jsx("sup",{children:"T"})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-6",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Parameter Savings"}),e.jsxs("div",{className:"flex flex-col md:flex-row gap-8 items-center justify-center",children:[e.jsxs("div",{className:"bg-gray-900 p-6 rounded-lg border border-red-900/50 w-full md:w-1/2",children:[e.jsx("h4",{className:"text-red-400 font-bold mb-4 text-center",children:"Without Tying"}),e.jsxs("div",{className:"space-y-2 text-sm text-gray-300",children:[e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{children:"Input Embeddings:"}),e.jsxs("span",{children:[s.toFixed(1),"M"]})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{children:"Output Projection:"}),e.jsxs("span",{children:[s.toFixed(1),"M"]})]}),e.jsxs("div",{className:"border-t border-gray-700 pt-2 flex justify-between font-bold text-white",children:[e.jsx("span",{children:"Total Cost:"}),e.jsxs("span",{children:[(s*2).toFixed(1),"M"]})]})]})]}),e.jsxs("div",{className:"bg-gray-900 p-6 rounded-lg border border-emerald-900/50 w-full md:w-1/2 relative overflow-hidden",children:[e.jsx("div",{className:"absolute top-0 right-0 bg-emerald-600 text-white text-xs px-2 py-1",children:"GPT-2"}),e.jsx("h4",{className:"text-emerald-400 font-bold mb-4 text-center",children:"With Tying"}),e.jsxs("div",{className:"space-y-2 text-sm text-gray-300",children:[e.jsxs("div",{className:"flex justify-between",children:[e.jsx("span",{children:"Shared Matrix:"}),e.jsxs("span",{children:[s.toFixed(1),"M"]})]}),e.jsxs("div",{className:"flex justify-between opacity-50",children:[e.jsx("span",{children:"(Reused):"}),e.jsx("span",{children:"0M"})]}),e.jsxs("div",{className:"border-t border-gray-700 pt-2 flex justify-between font-bold text-white",children:[e.jsx("span",{children:"Total Cost:"}),e.jsxs("span",{children:[s.toFixed(1),"M"]})]})]})]})]}),e.jsx("p",{className:"text-center text-gray-400 text-sm",children:"For GPT-2 Small (124M params), the embedding matrix accounts for ~30% of all parameters!"})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"What is the primary benefit of weight tying in language models?"}),e.jsx("textarea",{value:r,onChange:u=>d(u.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:x,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),a&&e.jsx("div",{className:`p-3 rounded ${a.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:a})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Training Optimizations â†’"})]})]})}function de({onComplete:h,onNext:g,onPrev:m}){const[r,d]=l.useState(""),[a,i]=l.useState(""),o=()=>{const c=r.toLowerCase().includes("memory")||r.toLowerCase().includes("ram")||r.toLowerCase().includes("vram");i(c?"âœ“ Correct! Gradient accumulation allows training with large effective batch sizes even on GPUs with limited memory.":"âœ— Try again. What resource constraint does gradient accumulation help overcome?"),c&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 8: Training Optimizations"}),e.jsx("p",{className:"text-gray-400",children:"How to train massive models efficiently"})]}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-6",children:[e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-3 border border-gray-700",children:[e.jsx("h3",{className:"text-lg font-semibold text-emerald-400",children:"Gradient Accumulation"}),e.jsx("p",{className:"text-sm text-gray-300",children:"Simulates a larger batch size by running multiple small batches and summing their gradients before updating weights."}),e.jsxs("div",{className:"bg-gray-900 p-3 rounded text-xs font-mono text-gray-400",children:["For i in range(accumulation_steps):",e.jsx("br",{}),"Â Â loss = model(batch)",e.jsx("br",{}),"Â Â loss.backward()",e.jsx("br",{}),"optimizer.step()",e.jsx("br",{}),"optimizer.zero_grad()"]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-3 border border-gray-700",children:[e.jsx("h3",{className:"text-lg font-semibold text-emerald-400",children:"Mixed Precision (FP16)"}),e.jsx("p",{className:"text-sm text-gray-300",children:"Uses 16-bit floating point numbers for activations and gradients to save memory and speed up computation, while keeping a 32-bit copy of weights for stability."}),e.jsxs("div",{className:"flex gap-2 text-xs",children:[e.jsx("span",{className:"bg-blue-900 text-blue-200 px-2 py-1 rounded",children:"2x Faster"}),e.jsx("span",{className:"bg-green-900 text-green-200 px-2 py-1 rounded",children:"50% Memory"})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-3 border border-gray-700",children:[e.jsx("h3",{className:"text-lg font-semibold text-emerald-400",children:"Gradient Clipping"}),e.jsx("p",{className:"text-sm text-gray-300",children:'Caps the norm of gradient vectors to prevent "exploding gradients" which can destabilize training.'}),e.jsxs("div",{className:"bg-gray-900 p-3 rounded text-xs font-mono text-gray-400",children:["torch.nn.utils.clip_grad_norm_(",e.jsx("br",{}),"Â Â model.parameters(), max_norm=1.0",e.jsx("br",{}),")"]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-3 border border-gray-700",children:[e.jsx("h3",{className:"text-lg font-semibold text-emerald-400",children:"Cosine Decay with Warmup"}),e.jsx("p",{className:"text-sm text-gray-300",children:"Linearly increases LR from 0 to max (warmup), then decreases it following a cosine curve. Helps stability at start and convergence at end."}),e.jsx("svg",{viewBox:"0 0 100 40",className:"w-full h-16 bg-gray-900 rounded",children:e.jsx("path",{d:"M0,40 L10,5 Q50,5 100,40",fill:"none",stroke:"#10b981",strokeWidth:"2"})})]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"If your GPU runs out of memory (OOM) with batch size 32, but you want the training stability of batch size 32, which technique should you use?"}),e.jsx("textarea",{value:r,onChange:c=>d(c.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:o,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),a&&e.jsx("div",{className:`p-3 rounded ${a.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:a})]}),e.jsxs("div",{className:"flex justify-between",children:[e.jsx("button",{onClick:m,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"}),e.jsx("button",{onClick:g,className:"px-6 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-semibold transition-colors",children:"Next: Inference Optimizations â†’"})]})]})}function ce({onComplete:h,onPrev:g}){const[m,r]=l.useState(""),[d,a]=l.useState(""),i=()=>{const o=m.toLowerCase().includes("compute")||m.toLowerCase().includes("calculation")||m.toLowerCase().includes("redundant");a(o?"âœ“ Correct! KV Caching prevents re-computing Key and Value vectors for tokens we have already processed.":"âœ— Try again. Why is it wasteful to re-process the entire prompt for every new token generated?"),o&&h()};return e.jsxs("div",{className:"space-y-8",children:[e.jsxs("div",{children:[e.jsx("h2",{className:"text-3xl font-bold mb-2",children:"Step 9: Inference Optimizations"}),e.jsx("p",{className:"text-gray-400",children:"Making generation fast"})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"KV Caching"}),e.jsxs("p",{className:"text-gray-300",children:["When generating text token-by-token, we don't need to recompute the Keys and Values for previous tokens. We can ",e.jsx("strong",{children:"cache"})," them."]}),e.jsxs("div",{className:"flex flex-col gap-4 mt-4",children:[e.jsxs("div",{className:"bg-gray-900 p-4 rounded border border-red-900/30",children:[e.jsx("div",{className:"text-red-400 font-bold text-sm mb-2",children:"Without Cache (O(NÂ²) complexity)"}),e.jsxs("div",{className:"flex gap-1 text-xs font-mono text-gray-500",children:[e.jsx("span",{className:"bg-gray-700 px-1 rounded text-white",children:"The"}),e.jsx("span",{className:"bg-gray-700 px-1 rounded text-white",children:"cat"}),e.jsx("span",{className:"bg-gray-700 px-1 rounded text-white",children:"sat"}),e.jsx("span",{className:"bg-emerald-600 px-1 rounded text-white",children:"on"})]}),e.jsx("div",{className:"mt-1 text-xs text-gray-400",children:'Recomputes attention for "The", "cat", "sat"'})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded border border-emerald-900/30",children:[e.jsx("div",{className:"text-emerald-400 font-bold text-sm mb-2",children:"With Cache (O(N) complexity)"}),e.jsxs("div",{className:"flex gap-1 text-xs font-mono text-gray-500",children:[e.jsx("span",{className:"bg-gray-800 px-1 rounded text-gray-400 border border-emerald-500/50",children:"The"}),e.jsx("span",{className:"bg-gray-800 px-1 rounded text-gray-400 border border-emerald-500/50",children:"cat"}),e.jsx("span",{className:"bg-gray-800 px-1 rounded text-gray-400 border border-emerald-500/50",children:"sat"}),e.jsx("span",{className:"bg-emerald-600 px-1 rounded text-white",children:"on"})]}),e.jsx("div",{className:"mt-1 text-xs text-gray-400",children:'Uses cached K/V for "The", "cat", "sat". Only computes "on".'})]})]})]}),e.jsxs("div",{className:"bg-gray-800 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-emerald-400",children:"Sampling Strategies"}),e.jsx("p",{className:"text-gray-300",children:"How do we pick the next token from the probabilities?"}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-4",children:[e.jsxs("div",{className:"bg-gray-900 p-4 rounded",children:[e.jsx("div",{className:"font-bold text-white mb-1",children:"Greedy"}),e.jsx("div",{className:"text-xs text-gray-400",children:"Always pick the highest probability token. Can be repetitive."})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded",children:[e.jsx("div",{className:"font-bold text-white mb-1",children:"Top-k"}),e.jsxs("div",{className:"text-xs text-gray-400",children:["Sample from the top ",e.jsx("em",{children:"k"})," most likely tokens."]})]}),e.jsxs("div",{className:"bg-gray-900 p-4 rounded",children:[e.jsx("div",{className:"font-bold text-white mb-1",children:"Nucleus (Top-p)"}),e.jsxs("div",{className:"text-xs text-gray-400",children:["Sample from the smallest set of tokens whose cumulative probability exceeds ",e.jsx("em",{children:"p"}),"."]})]})]})]}),e.jsxs("div",{className:"bg-blue-900 bg-opacity-30 border border-blue-700 rounded-lg p-6 space-y-4",children:[e.jsx("h3",{className:"text-xl font-semibold text-blue-400",children:"ðŸ“ Exercise"}),e.jsx("p",{className:"text-gray-300",children:"Why does KV Caching make text generation significantly faster?"}),e.jsx("textarea",{value:m,onChange:o=>r(o.target.value),className:"w-full bg-gray-700 text-white px-4 py-2 rounded border border-gray-600 focus:border-blue-500 focus:outline-none h-24",placeholder:"Your answer..."}),e.jsx("button",{onClick:i,className:"px-6 py-2 bg-blue-600 hover:bg-blue-700 rounded font-semibold transition-colors",children:"Check Answer"}),d&&e.jsx("div",{className:`p-3 rounded ${d.startsWith("âœ“")?"bg-green-900 text-green-200":"bg-red-900 text-red-200"}`,children:d})]}),e.jsxs("div",{className:"bg-emerald-900 bg-opacity-30 border border-emerald-700 rounded-lg p-8 text-center space-y-4 mt-8",children:[e.jsx("h2",{className:"text-3xl font-bold text-emerald-400",children:"ðŸŽ‰ Course Complete!"}),e.jsx("p",{className:"text-gray-300",children:"You've explored the architecture and optimizations of GPT-2."}),e.jsx("button",{onClick:()=>window.location.href="/",className:"px-8 py-3 bg-emerald-600 hover:bg-emerald-700 rounded font-bold transition-colors",children:"Start Over"})]}),e.jsx("div",{className:"flex justify-start",children:e.jsx("button",{onClick:g,className:"px-6 py-3 bg-gray-700 hover:bg-gray-600 rounded font-semibold transition-colors",children:"â† Previous"})})]})}function he(){var c;const[h,g]=l.useState(new Set),m=V(),r=Y(),d=((c=A.find(s=>s.path===r.pathname))==null?void 0:c.id)||1,a=s=>{g(x=>new Set([...x,s]))},i=()=>{const s=A.findIndex(x=>x.id===d);s<A.length-1&&m(A[s+1].path)},o=()=>{const s=A.findIndex(x=>x.id===d);s>0&&m(A[s-1].path)};return e.jsx("div",{className:"bg-gray-900 text-gray-100",children:e.jsxs("div",{className:"flex",children:[e.jsx("aside",{className:"w-64 bg-gray-800 min-h-[calc(100vh-73px)] border-r border-gray-700 p-4",children:e.jsx("nav",{children:e.jsx("ul",{className:"space-y-2",children:A.map(s=>e.jsx("li",{children:e.jsx("button",{onClick:()=>m(s.path),className:`w-full text-left px-4 py-3 rounded-lg transition-colors ${d===s.id?"bg-emerald-600 text-white":h.has(s.id)?"bg-gray-700 text-emerald-400":"bg-gray-700 text-gray-300 hover:bg-gray-600"}`,children:e.jsxs("div",{className:"flex items-center gap-2",children:[e.jsx("span",{className:"font-mono text-xs",children:s.id}),e.jsxs("div",{className:"flex-1",children:[e.jsx("div",{className:"font-semibold text-sm",children:s.title}),e.jsx("div",{className:"text-xs opacity-75",children:s.description})]}),h.has(s.id)&&e.jsx("span",{className:"text-emerald-400",children:"âœ“"})]})})},s.id))})})}),e.jsx("main",{className:"flex-1 p-8",children:e.jsx("div",{className:"max-w-4xl mx-auto",children:e.jsxs(D,{children:[e.jsx(k,{path:"/",element:e.jsx(R,{onComplete:()=>a(1),onNext:i})}),e.jsx(k,{path:"/step1",element:e.jsx(R,{onComplete:()=>a(1),onNext:i})}),e.jsx(k,{path:"/step2",element:e.jsx(re,{onComplete:()=>a(2),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step3",element:e.jsx(ne,{onComplete:()=>a(3),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step4",element:e.jsx(ae,{onComplete:()=>a(4),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step5",element:e.jsx(ie,{onComplete:()=>a(5),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step6",element:e.jsx(le,{onComplete:()=>a(6),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step7",element:e.jsx(oe,{onComplete:()=>a(7),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step8",element:e.jsx(de,{onComplete:()=>a(8),onNext:i,onPrev:o})}),e.jsx(k,{path:"/step9",element:e.jsx(ce,{onComplete:()=>a(9),onPrev:o})})]})})})]})})}export{he as default};
