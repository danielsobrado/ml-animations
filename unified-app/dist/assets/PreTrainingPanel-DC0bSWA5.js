import{r as i,j as e,B as f}from"./index-CsxpOLHd.js";import{E as y}from"./eye-off-Dh3RwD2Q.js";import{P as w}from"./pause-BMcOX1vk.js";import{P as _}from"./play-CIyTSByC.js";import{R as P}from"./rotate-ccw-xVnQluc9.js";function A(){const[s,b]=i.useState("mlm"),[l,p]=i.useState(0),[n,h]=i.useState(0),[o,x]=i.useState(!1),[M,L]=i.useState(!1),j=[{title:"Original Sentence",description:"Start with a sentence from the training corpus."},{title:"Random Masking (15%)",description:"15% of tokens are selected for masking. Of these: 80% ‚Üí [MASK], 10% ‚Üí random word, 10% ‚Üí unchanged."},{title:"Predict Masked Tokens",description:"BERT predicts the original tokens at masked positions using bidirectional context."},{title:"Compute Loss",description:"Cross-entropy loss only for masked tokens. Learn to understand language structure."}],N=[{title:"Sample Sentence Pairs",description:"Create pairs: 50% consecutive sentences (IsNext), 50% random sentences (NotNext)."},{title:"Add Special Tokens",description:"[CLS] + Sentence A + [SEP] + Sentence B + [SEP]. Segment embeddings distinguish A and B."},{title:"Predict Relationship",description:"Use [CLS] token output to predict if B follows A (binary classification)."},{title:"Learn Document Understanding",description:"Model learns inter-sentence relationships useful for QA, NLI tasks."}],c={original:["The","quick","brown","fox","jumps","over","the","lazy","dog"],masked:["The","[MASK]","brown","[MASK]","jumps","over","the","lazy","[MASK]"],predictions:["The","quick","brown","fox","jumps","over","the","lazy","dog"],maskedIndices:[1,3,8]},m={positive:{sentA:"The cat sat on the mat.",sentB:"It was very comfortable."},negative:{sentA:"The cat sat on the mat.",sentB:"Python is a programming language."}};i.useEffect(()=>{if(o){const r=s==="mlm"?j:N,t=s==="mlm"?p:h,a=s==="mlm"?l:n,k=setInterval(()=>{a>=r.length-1?x(!1):t(S=>S+1)},2500);return()=>clearInterval(k)}},[o,s,l,n]);const g=()=>{p(0),h(0),x(!1)},u=s==="mlm"?j:N,d=s==="mlm"?l:n,v=s==="mlm"?p:h;return e.jsxs("div",{className:"space-y-6",children:[e.jsxs("div",{className:"text-center",children:[e.jsxs("h2",{className:"text-3xl font-bold mb-2",children:["BERT ",e.jsx("span",{className:"text-yellow-400",children:"Pre-Training"})," Objectives"]}),e.jsx("p",{className:"text-gray-400",children:"Two self-supervised tasks: Masked Language Model (MLM) & Next Sentence Prediction (NSP)"})]}),e.jsxs("div",{className:"flex justify-center gap-4",children:[e.jsxs("button",{onClick:()=>{b("mlm"),g()},className:`flex items-center gap-2 px-6 py-3 rounded-xl transition-all ${s==="mlm"?"bg-yellow-600 text-white scale-105":"bg-white/10 hover:bg-white/20"}`,children:[e.jsx(y,{size:20}),e.jsxs("div",{className:"text-left",children:[e.jsx("p",{className:"font-bold",children:"MLM"}),e.jsx("p",{className:"text-xs opacity-75",children:"Masked Language Model"})]})]}),e.jsxs("button",{onClick:()=>{b("nsp"),g()},className:`flex items-center gap-2 px-6 py-3 rounded-xl transition-all ${s==="nsp"?"bg-purple-600 text-white scale-105":"bg-white/10 hover:bg-white/20"}`,children:[e.jsx(f,{size:20}),e.jsxs("div",{className:"text-left",children:[e.jsx("p",{className:"font-bold",children:"NSP"}),e.jsx("p",{className:"text-xs opacity-75",children:"Next Sentence Prediction"})]})]})]}),e.jsxs("div",{className:"flex justify-center gap-3",children:[e.jsxs("button",{onClick:()=>x(!o),className:`flex items-center gap-2 px-4 py-2 rounded-lg transition-colors ${s==="mlm"?"bg-yellow-600 hover:bg-yellow-700":"bg-purple-600 hover:bg-purple-700"}`,children:[o?e.jsx(w,{size:18}):e.jsx(_,{size:18}),o?"Pause":"Play Animation"]}),e.jsxs("button",{onClick:g,className:"flex items-center gap-2 px-4 py-2 bg-white/10 hover:bg-white/20 rounded-lg transition-colors",children:[e.jsx(P,{size:18}),"Reset"]})]}),e.jsx("div",{className:"flex justify-center gap-2",children:u.map((r,t)=>e.jsx("button",{onClick:()=>{v(t),x(!1)},className:`w-8 h-8 rounded-full flex items-center justify-center text-sm font-medium transition-all ${t===d?s==="mlm"?"bg-yellow-500 text-black scale-110":"bg-purple-500 text-white scale-110":t<d?s==="mlm"?"bg-yellow-900 text-yellow-300":"bg-purple-900 text-purple-300":"bg-white/10 text-gray-500"}`,children:t+1},t))}),e.jsxs("div",{className:`rounded-xl p-4 border ${s==="mlm"?"bg-yellow-900/20 border-yellow-500/30":"bg-purple-900/20 border-purple-500/30"}`,children:[e.jsxs("h3",{className:`font-bold ${s==="mlm"?"text-yellow-400":"text-purple-400"}`,children:["Step ",d+1,": ",u[d].title]}),e.jsx("p",{className:"text-gray-300 mt-1",children:u[d].description})]}),s==="mlm"&&e.jsxs("div",{className:"bg-black/30 rounded-2xl p-6 border border-white/10",children:[e.jsxs("h3",{className:"text-lg font-bold mb-4 text-yellow-400 flex items-center gap-2",children:[e.jsx(y,{size:20}),"Masked Language Model (MLM)"]}),e.jsxs("div",{className:"space-y-6",children:[e.jsxs("div",{className:`transition-all duration-500 ${l>=0?"opacity-100":"opacity-30"}`,children:[e.jsx("p",{className:"text-sm text-gray-400 mb-2",children:"Original sentence:"}),e.jsx("div",{className:"flex flex-wrap gap-2",children:c.original.map((r,t)=>e.jsx("span",{className:"px-3 py-2 bg-blue-600/30 rounded text-blue-300 font-mono",children:r},t))})]}),e.jsxs("div",{className:`transition-all duration-500 ${l>=1?"opacity-100":"opacity-30"}`,children:[e.jsx("p",{className:"text-sm text-gray-400 mb-2",children:"After masking (15% tokens):"}),e.jsx("div",{className:"flex flex-wrap gap-2",children:c.masked.map((r,t)=>{const a=c.maskedIndices.includes(t);return e.jsx("span",{className:`px-3 py-2 rounded font-mono ${a?"bg-red-600/50 text-red-300 border-2 border-red-500":"bg-gray-700/30 text-gray-400"}`,children:r},t)})})]}),e.jsxs("div",{className:`transition-all duration-500 ${l>=2?"opacity-100":"opacity-30"}`,children:[e.jsx("p",{className:"text-sm text-gray-400 mb-2",children:"BERT predicts:"}),e.jsx("div",{className:"flex flex-wrap gap-2",children:c.predictions.map((r,t)=>{const a=c.maskedIndices.includes(t);return e.jsxs("div",{className:"flex flex-col items-center",children:[e.jsx("span",{className:`px-3 py-2 rounded font-mono ${a?"bg-green-600/50 text-green-300 border-2 border-green-500":"bg-gray-700/30 text-gray-400"}`,children:r}),a&&l>=3&&e.jsx("span",{className:"text-xs text-green-400 mt-1",children:"‚úì correct"})]},t)})})]}),l>=3&&e.jsxs("div",{className:"bg-orange-900/20 border border-orange-500/30 rounded-lg p-3",children:[e.jsxs("p",{className:"text-sm text-orange-300",children:[e.jsx("strong",{children:"MLM Loss:"})," Cross-entropy computed only for masked positions"]}),e.jsx("code",{className:"text-xs text-gray-400 mt-1 block",children:"Loss = -Œ£ log P(original_token | context) for masked positions only"})]})]}),e.jsxs("div",{className:"mt-6 grid grid-cols-3 gap-3",children:[e.jsxs("div",{className:"bg-red-900/20 rounded-lg p-3 border border-red-500/30",children:[e.jsx("p",{className:"text-2xl font-bold text-red-400",children:"80%"}),e.jsx("p",{className:"text-xs text-gray-400",children:"Replace with [MASK]"})]}),e.jsxs("div",{className:"bg-orange-900/20 rounded-lg p-3 border border-orange-500/30",children:[e.jsx("p",{className:"text-2xl font-bold text-orange-400",children:"10%"}),e.jsx("p",{className:"text-xs text-gray-400",children:"Replace with random"})]}),e.jsxs("div",{className:"bg-gray-800/50 rounded-lg p-3 border border-gray-500/30",children:[e.jsx("p",{className:"text-2xl font-bold text-gray-400",children:"10%"}),e.jsx("p",{className:"text-xs text-gray-400",children:"Keep unchanged"})]})]})]}),s==="nsp"&&e.jsxs("div",{className:"bg-black/30 rounded-2xl p-6 border border-white/10",children:[e.jsxs("h3",{className:"text-lg font-bold mb-4 text-purple-400 flex items-center gap-2",children:[e.jsx(f,{size:20}),"Next Sentence Prediction (NSP)"]}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4 mb-6",children:[e.jsxs("div",{className:`p-4 rounded-xl border-2 transition-all duration-500 ${n>=0?"bg-green-900/20 border-green-500/50":"bg-gray-800/30 border-gray-600/30"}`,children:[e.jsx("p",{className:"text-sm font-medium text-green-400 mb-2",children:"‚úì Positive (50%): IsNext"}),e.jsxs("div",{className:`transition-all ${n>=1?"opacity-100":"opacity-50"}`,children:[e.jsx("p",{className:"text-xs text-gray-400",children:"[CLS]"}),e.jsx("p",{className:"text-blue-300 text-sm",children:m.positive.sentA}),e.jsx("p",{className:"text-xs text-gray-400",children:"[SEP]"}),e.jsx("p",{className:"text-green-300 text-sm",children:m.positive.sentB}),e.jsx("p",{className:"text-xs text-gray-400",children:"[SEP]"})]}),n>=2&&e.jsx("div",{className:"mt-3 bg-green-600/30 rounded px-2 py-1 inline-block",children:e.jsx("span",{className:"text-sm text-green-300",children:"Prediction: IsNext ‚úì"})})]}),e.jsxs("div",{className:`p-4 rounded-xl border-2 transition-all duration-500 ${n>=0?"bg-red-900/20 border-red-500/50":"bg-gray-800/30 border-gray-600/30"}`,children:[e.jsx("p",{className:"text-sm font-medium text-red-400 mb-2",children:"‚úó Negative (50%): NotNext"}),e.jsxs("div",{className:`transition-all ${n>=1?"opacity-100":"opacity-50"}`,children:[e.jsx("p",{className:"text-xs text-gray-400",children:"[CLS]"}),e.jsx("p",{className:"text-blue-300 text-sm",children:m.negative.sentA}),e.jsx("p",{className:"text-xs text-gray-400",children:"[SEP]"}),e.jsx("p",{className:"text-orange-300 text-sm",children:m.negative.sentB}),e.jsx("p",{className:"text-xs text-gray-400",children:"[SEP]"})]}),n>=2&&e.jsx("div",{className:"mt-3 bg-red-600/30 rounded px-2 py-1 inline-block",children:e.jsx("span",{className:"text-sm text-red-300",children:"Prediction: NotNext ‚úì"})})]})]}),n>=2&&e.jsxs("div",{className:"bg-purple-900/20 border border-purple-500/30 rounded-lg p-4",children:[e.jsx("p",{className:"text-sm text-purple-300 font-medium mb-2",children:"How NSP works:"}),e.jsxs("ol",{className:"text-xs text-gray-400 space-y-1 list-decimal list-inside",children:[e.jsx("li",{children:"The [CLS] token aggregates information from both sentences"}),e.jsx("li",{children:"[CLS] output ‚Üí Linear layer ‚Üí Binary classification (IsNext/NotNext)"}),e.jsx("li",{children:"Binary cross-entropy loss for this 2-class prediction"})]})]})]}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-yellow-900/20 rounded-xl p-4 border border-yellow-500/30",children:[e.jsx("h4",{className:"font-bold text-yellow-400 mb-3",children:"üìö Pre-Training Data"}),e.jsxs("ul",{className:"text-sm text-gray-300 space-y-2",children:[e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"BookCorpus:"})," ~800M words (11,038 books)"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"English Wikipedia:"})," ~2,500M words"]}),e.jsx("li",{children:"‚Ä¢ Document-level corpus for NSP task"}),e.jsx("li",{children:"‚Ä¢ Total: ~3.3 billion words"})]})]}),e.jsxs("div",{className:"bg-blue-900/20 rounded-xl p-4 border border-blue-500/30",children:[e.jsx("h4",{className:"font-bold text-blue-400 mb-3",children:"‚öôÔ∏è Pre-Training Config"}),e.jsxs("ul",{className:"text-sm text-gray-300 space-y-2",children:[e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Batch size:"})," 256 sequences"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Max length:"})," 512 tokens"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Steps:"})," 1,000,000"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Time:"})," ~4 days on 16 TPU chips"]}),e.jsxs("li",{children:["‚Ä¢ ",e.jsx("strong",{children:"Optimizer:"})," Adam (lr=1e-4)"]})]})]})]}),e.jsxs("div",{className:"bg-gradient-to-r from-yellow-900/20 to-purple-900/20 rounded-xl p-4 border border-white/20",children:[e.jsx("h4",{className:"font-bold text-white mb-3",children:"üéØ Total Pre-Training Loss"}),e.jsx("div",{className:"bg-black/30 rounded-lg p-4 text-center",children:e.jsxs("code",{className:"text-lg",children:[e.jsx("span",{className:"text-white",children:"L"}),e.jsx("span",{className:"text-gray-400",children:"_total"}),e.jsx("span",{className:"text-white",children:" = "}),e.jsx("span",{className:"text-yellow-400",children:"L"}),e.jsx("span",{className:"text-yellow-300",children:"_MLM"}),e.jsx("span",{className:"text-white",children:" + "}),e.jsx("span",{className:"text-purple-400",children:"L"}),e.jsx("span",{className:"text-purple-300",children:"_NSP"})]})}),e.jsx("p",{className:"text-xs text-gray-400 mt-2 text-center",children:"Both losses are weighted equally. MLM provides language understanding, NSP provides discourse understanding."})]}),e.jsxs("div",{className:"bg-orange-900/20 rounded-xl p-4 border border-orange-500/30",children:[e.jsx("h4",{className:"font-bold text-orange-400 mb-2",children:"‚ö†Ô∏è Note on NSP"}),e.jsx("p",{className:"text-sm text-gray-300",children:"Later research (RoBERTa, ALBERT) found that NSP may not be necessary and can even hurt performance. These models use only MLM or modified versions like Sentence Order Prediction (SOP)."})]}),e.jsxs("div",{className:"bg-black/40 rounded-xl p-4 border border-white/10",children:[e.jsx("p",{className:"text-sm text-gray-400 mb-3",children:"üêç PyTorch Pre-Training Heads:"}),e.jsx("pre",{className:"text-sm overflow-x-auto",children:e.jsx("code",{className:"text-cyan-300",children:`class BertPreTrainingHeads(nn.Module):
    def __init__(self, config):
        super().__init__()
        # MLM Head: predict masked tokens
        self.mlm_head = nn.Sequential(
            nn.Linear(config.hidden_size, config.hidden_size),
            nn.GELU(),
            nn.LayerNorm(config.hidden_size),
            nn.Linear(config.hidden_size, config.vocab_size)  # 768 ‚Üí 30522
        )
        # NSP Head: binary classification from [CLS]
        self.nsp_head = nn.Linear(config.hidden_size, 2)  # 768 ‚Üí 2
    
    def forward(self, sequence_output, pooled_output):
        # sequence_output: [batch, seq_len, 768] - for MLM
        # pooled_output: [batch, 768] - [CLS] token output for NSP
        
        mlm_logits = self.mlm_head(sequence_output)  # [batch, seq_len, vocab_size]
        nsp_logits = self.nsp_head(pooled_output)    # [batch, 2]
        
        return mlm_logits, nsp_logits

# Training loop (simplified)
def compute_loss(model, batch):
    outputs = model(batch['input_ids'], batch['attention_mask'], batch['token_type_ids'])
    mlm_logits, nsp_logits = outputs
    
    # MLM loss (only for masked positions)
    mlm_loss = F.cross_entropy(
        mlm_logits.view(-1, vocab_size),
        batch['mlm_labels'].view(-1),
        ignore_index=-100  # Ignore non-masked tokens
    )
    
    # NSP loss
    nsp_loss = F.cross_entropy(nsp_logits, batch['nsp_labels'])
    
    return mlm_loss + nsp_loss`})})]})]})}export{A as default};
