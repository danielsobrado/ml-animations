import{r as h,j as e,L as v}from"./index-CsxpOLHd.js";import{C as y}from"./check-circle-C5pajHEW.js";import{X as z}from"./x-circle-guWBBJ3U.js";import{R as S}from"./refresh-cw-CbjIGqua.js";const c=[{id:1,question:"Why do modern LLMs use subword tokenization instead of word-level?",options:["It's faster to compute","It can handle rare/unknown words by breaking them into known pieces","It produces fewer tokens","It requires less memory"],correct:1,explanation:'Subword tokenization handles Out-of-Vocabulary (OOV) words by breaking them into known subword units. For example, "unhappiness" becomes "un" + "happi" + "ness".'},{id:2,question:'What does the "##" prefix mean in WordPiece tokenization?',options:["It marks the start of a new word","It indicates a special token","It means this token continues the previous word (not a word start)","It represents a number"],correct:2,explanation:'In WordPiece, "##" indicates that this subword is a continuation of the previous token, not the start of a new word. E.g., "playing" ‚Üí ["play", "##ing"]'},{id:3,question:"In BPE, what determines which token pairs get merged?",options:["Alphabetical order","The length of the resulting token","Frequency - most common pairs are merged first","Random selection"],correct:2,explanation:"BPE merges the most frequently occurring adjacent token pairs. This creates a vocabulary of common subwords that efficiently represent the training corpus."},{id:4,question:"Which tokenization method does GPT-4 primarily use?",options:["Character-level tokenization","Word-level tokenization","BPE (Byte Pair Encoding)","WordPiece"],correct:2,explanation:"GPT models use BPE (specifically cl100k_base for GPT-4), which efficiently balances vocabulary size with the ability to represent any text."},{id:5,question:"What happens when a tokenizer encounters a word not in its vocabulary?",options:["It throws an error","It skips the word","It breaks the word into smaller known subwords or characters","It replaces it with a random word"],correct:2,explanation:"Subword tokenizers can represent ANY text by breaking unknown words into known subword pieces or even individual characters as a fallback."}],P=m=>{const a=[];return m.split(/(\s+)/).forEach(i=>{if(i.match(/^\s+$/))a.push({token:i===" "?"‚ñÅ":"‚ñÅ".repeat(i.length),type:"space"});else if(i.length<=3)a.push({token:i,type:"word"});else{const x=["ing","tion","ment","ness","ful","less","able","ly","ed","er","est","s","es"];let n=i,o=!0;const p=["un","re","pre","dis","mis","over","under"];for(const t of p)if(n.toLowerCase().startsWith(t)&&n.length>t.length+2){a.push({token:t,type:"prefix"}),n=n.slice(t.length),o=!1;break}let b=null;for(const t of x)if(n.toLowerCase().endsWith(t)&&n.length>t.length+1){b=t;break}if(b){const t=n.slice(0,-b.length);a.push({token:o?t:"##"+t,type:"stem"}),a.push({token:"##"+b,type:"suffix"})}else a.push({token:o?n:"##"+n,type:"word"})}}),a};function E(){const[m,a]=h.useState("quiz"),[d,i]=h.useState(0),[x,n]=h.useState(null),[o,p]=h.useState(!1),[b,t]=h.useState(0),[u,g]=h.useState("The unhappiness of tokenization is overwhelming"),[f,j]=h.useState([]);h.useEffect(()=>{j(P(u))},[u]);const w=s=>{n(s),p(!0),s===c[d].correct&&t(r=>r+1)},k=()=>{d<c.length-1&&(i(s=>s+1),n(null),p(!1))},N=()=>{i(0),n(null),p(!1),t(0)},l=c[d];return e.jsx("div",{className:"p-8 h-full",children:e.jsxs("div",{className:"max-w-4xl mx-auto",children:[e.jsxs("div",{className:"text-center mb-6",children:[e.jsx("h2",{className:"text-3xl font-bold text-indigo-900 mb-2",children:"Practice Lab"}),e.jsx("p",{className:"text-slate-600",children:"Test your understanding of tokenization"})]}),e.jsxs("div",{className:"flex justify-center gap-4 mb-8",children:[e.jsx("button",{onClick:()=>a("quiz"),className:`px-6 py-2 rounded-lg font-bold transition-all ${m==="quiz"?"bg-indigo-600 text-white":"bg-slate-100 text-slate-600 hover:bg-slate-200"}`,children:"üìù Quiz"}),e.jsx("button",{onClick:()=>a("sandbox"),className:`px-6 py-2 rounded-lg font-bold transition-all ${m==="sandbox"?"bg-indigo-600 text-white":"bg-slate-100 text-slate-600 hover:bg-slate-200"}`,children:"üß™ Sandbox"})]}),m==="quiz"?e.jsxs("div",{className:"bg-slate-50 rounded-xl p-6",children:[e.jsxs("div",{className:"flex justify-between items-center mb-4",children:[e.jsxs("span",{className:"text-sm text-slate-600",children:["Question ",d+1," of ",c.length]}),e.jsxs("span",{className:"text-sm font-bold text-indigo-600",children:["Score: ",b,"/",c.length]})]}),e.jsx("div",{className:"w-full bg-slate-200 rounded-full h-2 mb-6",children:e.jsx("div",{className:"bg-indigo-600 h-2 rounded-full transition-all",style:{width:`${(d+1)/c.length*100}%`}})}),e.jsxs("div",{className:"bg-white rounded-lg p-6 mb-4 border",children:[e.jsx("h3",{className:"text-lg font-bold text-slate-800 mb-4",children:l.question}),e.jsx("div",{className:"space-y-3",children:l.options.map((s,r)=>e.jsx("button",{onClick:()=>!o&&w(r),disabled:o,className:`w-full p-3 rounded-lg border-2 text-left transition-all ${o?r===l.correct?"bg-green-100 border-green-400":r===x?"bg-red-100 border-red-400":"bg-slate-50 border-slate-200":x===r?"bg-indigo-50 border-indigo-400":"bg-white border-slate-200 hover:border-indigo-300"}`,children:e.jsxs("div",{className:"flex items-center gap-3",children:[o&&r===l.correct&&e.jsx(y,{className:"text-green-600",size:20}),o&&r===x&&r!==l.correct&&e.jsx(z,{className:"text-red-600",size:20}),e.jsx("span",{children:s})]})},r))})]}),o&&e.jsx("div",{className:`p-4 rounded-lg mb-4 ${x===l.correct?"bg-green-50 border border-green-200":"bg-amber-50 border border-amber-200"}`,children:e.jsxs("div",{className:"flex items-start gap-3",children:[e.jsx(v,{className:x===l.correct?"text-green-600":"text-amber-600",size:20}),e.jsx("p",{className:x===l.correct?"text-green-800":"text-amber-800",children:l.explanation})]})}),e.jsxs("div",{className:"flex justify-between",children:[e.jsxs("button",{onClick:N,className:"flex items-center gap-2 px-4 py-2 text-slate-600 hover:text-slate-800",children:[e.jsx(S,{size:16})," Reset"]}),o&&d<c.length-1&&e.jsx("button",{onClick:k,className:"px-6 py-2 bg-indigo-600 text-white rounded-lg font-bold hover:bg-indigo-700",children:"Next Question ‚Üí"}),o&&d===c.length-1&&e.jsxs("div",{className:"text-lg font-bold text-indigo-600",children:["Final Score: ",b,"/",c.length," üéâ"]})]})]}):e.jsxs("div",{className:"bg-slate-50 rounded-xl p-6",children:[e.jsx("h3",{className:"text-xl font-bold text-slate-800 mb-4",children:"Tokenization Sandbox"}),e.jsxs("div",{className:"mb-4",children:[e.jsx("label",{className:"block text-sm font-medium text-slate-700 mb-2",children:"Enter text to tokenize:"}),e.jsx("textarea",{value:u,onChange:s=>g(s.target.value),className:"w-full p-3 border-2 border-slate-200 rounded-lg focus:border-indigo-500 resize-none",rows:3,placeholder:"Type something to see how it gets tokenized..."})]}),e.jsx("div",{className:"flex flex-wrap gap-2 mb-6",children:["unhappiness","tokenization is cool","GPT-4 loves embeddings","ÿßŸÑŸÖÿ±ÿ≠ÿ®ÿß","üéâ emoji test"].map(s=>e.jsx("button",{onClick:()=>g(s),className:"px-3 py-1 text-xs bg-white border rounded-full hover:bg-slate-100",children:s},s))}),e.jsxs("div",{className:"bg-white rounded-lg p-4 border",children:[e.jsxs("div",{className:"flex justify-between items-center mb-3",children:[e.jsxs("h4",{className:"font-bold text-slate-700",children:["Tokens (",f.length,")"]}),e.jsxs("span",{className:"text-xs text-slate-500",children:["~",(u.length/4).toFixed(0)," GPT tokens estimate"]})]}),e.jsx("div",{className:"flex flex-wrap gap-2",children:f.map((s,r)=>e.jsxs("div",{className:`px-3 py-1 rounded-lg font-mono text-sm flex items-center gap-1 ${s.type==="prefix"?"bg-orange-100 border-2 border-orange-300":s.type==="suffix"?"bg-purple-100 border-2 border-purple-300":s.type==="stem"?"bg-blue-100 border-2 border-blue-300":s.type==="space"?"bg-slate-100 border-2 border-slate-300":"bg-green-100 border-2 border-green-300"}`,children:[e.jsx("span",{className:"text-xs text-slate-500",children:r}),s.token]},r))})]}),e.jsxs("div",{className:"mt-4 flex flex-wrap gap-4 text-xs",children:[e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("span",{className:"w-4 h-4 bg-orange-100 border-2 border-orange-300 rounded"}),e.jsx("span",{children:"Prefix"})]}),e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("span",{className:"w-4 h-4 bg-blue-100 border-2 border-blue-300 rounded"}),e.jsx("span",{children:"Stem"})]}),e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("span",{className:"w-4 h-4 bg-purple-100 border-2 border-purple-300 rounded"}),e.jsx("span",{children:"Suffix (##)"})]}),e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("span",{className:"w-4 h-4 bg-green-100 border-2 border-green-300 rounded"}),e.jsx("span",{children:"Word"})]}),e.jsxs("div",{className:"flex items-center gap-1",children:[e.jsx("span",{className:"w-4 h-4 bg-slate-100 border-2 border-slate-300 rounded"}),e.jsx("span",{children:"Space"})]})]})]})]})})}export{E as default};
