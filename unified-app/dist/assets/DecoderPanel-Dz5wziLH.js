import{r as i,j as e,l as b,x as d}from"./index-CsxpOLHd.js";import{P as w}from"./pause-BMcOX1vk.js";import{P as _}from"./play-CIyTSByC.js";import{R as S}from"./rotate-ccw-xVnQluc9.js";function L(){const[t,c]=i.useState(0),[l,o]=i.useState(!1),[r,g]=i.useState(!1),p=i.useRef(null),s=[{title:"Latent Vector z",description:"The sampled latent vector z (or a generated sample from N(0,I)) enters the decoder.",highlight:"latent"},{title:"First Hidden Layer",description:"Linear transformation expands z from 20 dimensions to 200, beginning the reconstruction process.",highlight:"hidden1"},{title:"Second Hidden Layer",description:"Further expansion to 400 dimensions with ReLU activation, adding capacity for complex features.",highlight:"hidden2"},{title:"Output Layer",description:"Final linear layer maps to 784 dimensions (28√ó28 image). Sigmoid squashes values to [0,1] for pixel intensities.",highlight:"output"},{title:"Reconstructed Image",description:"The 784-dimensional output is reshaped to 28√ó28 to form the reconstructed (or generated) image.",highlight:"image"}];i.useEffect(()=>(l&&(p.current=setInterval(()=>{c(n=>n>=s.length-1?(o(!1),n):n+1)},2e3)),()=>clearInterval(p.current)),[l]);const j=()=>{c(0),o(!1)},m=({count:n,width:a,color:y,label:v,active:h,sublabel:f})=>e.jsxs("div",{className:"flex flex-col items-center",children:[e.jsx("div",{className:`relative transition-all duration-500 ${h?"scale-110":"scale-100"}`,style:{width:`${a}px`},children:e.jsxs("div",{className:`h-32 rounded-lg ${y} ${h?"ring-2 ring-white ring-offset-2 ring-offset-transparent":""} flex flex-col items-center justify-center transition-all`,children:[e.jsx("p",{className:"text-2xl font-bold",children:n}),e.jsx("p",{className:"text-xs opacity-80",children:"neurons"})]})}),e.jsx("p",{className:`mt-2 text-sm font-medium transition-colors ${h?"text-white":"text-gray-400"}`,children:v}),f&&e.jsx("p",{className:"text-xs text-gray-500",children:f})]}),x=()=>Array(16).fill(0).map(()=>Math.random()>.4?1:0),[N,u]=i.useState(x());return e.jsxs("div",{className:"space-y-6",children:[e.jsxs("div",{className:"text-center",children:[e.jsxs("h2",{className:"text-3xl font-bold mb-2",children:["Decoder: ",e.jsx("span",{className:"text-orange-400",children:"From Latent to Data"})]}),e.jsx("p",{className:"text-gray-400",children:"The decoder learns to reconstruct data from latent representations"})]}),e.jsxs("div",{className:"flex justify-center gap-4",children:[e.jsx("button",{onClick:()=>g(!1),className:`px-4 py-2 rounded-lg font-medium transition-all ${r?"bg-white/10 text-gray-400":"bg-orange-600 text-white"}`,children:"Reconstruction Mode"}),e.jsxs("button",{onClick:()=>{g(!0),u(x())},className:`flex items-center gap-2 px-4 py-2 rounded-lg font-medium transition-all ${r?"bg-purple-600 text-white":"bg-white/10 text-gray-400"}`,children:[e.jsx(b,{size:18}),"Generation Mode"]})]}),e.jsx("div",{className:`rounded-xl p-4 border ${r?"bg-purple-900/20 border-purple-500/30":"bg-orange-900/20 border-orange-500/30"}`,children:r?e.jsxs("p",{className:"text-gray-300",children:[e.jsx("strong",{className:"text-purple-400",children:"Generation Mode:"})," Sample z ~ N(0, I) directly (no encoder needed!) and pass through decoder to generate new data that looks like the training distribution."]}):e.jsxs("p",{className:"text-gray-300",children:[e.jsx("strong",{className:"text-orange-400",children:"Reconstruction Mode:"})," The encoder produces z from input x, then the decoder reconstructs xÃÇ ‚âà x. Loss = how different is xÃÇ from x?"]})}),e.jsxs("div",{className:"flex justify-center gap-3",children:[e.jsxs("button",{onClick:()=>o(!l),className:"flex items-center gap-2 px-4 py-2 bg-orange-600 hover:bg-orange-700 rounded-lg transition-colors",children:[l?e.jsx(w,{size:18}):e.jsx(_,{size:18}),l?"Pause":"Play Animation"]}),e.jsxs("button",{onClick:j,className:"flex items-center gap-2 px-4 py-2 bg-white/10 hover:bg-white/20 rounded-lg transition-colors",children:[e.jsx(S,{size:18}),"Reset"]}),r&&e.jsxs("button",{onClick:()=>u(x()),className:"flex items-center gap-2 px-4 py-2 bg-purple-600 hover:bg-purple-700 rounded-lg transition-colors",children:[e.jsx(b,{size:18}),"New Sample"]})]}),e.jsx("div",{className:"flex justify-center gap-2",children:s.map((n,a)=>e.jsx("button",{onClick:()=>{c(a),o(!1)},className:`w-8 h-8 rounded-full flex items-center justify-center text-sm font-medium transition-all ${a===t?"bg-orange-500 text-white scale-110":a<t?"bg-orange-900 text-orange-300":"bg-white/10 text-gray-500"}`,children:a+1},a))}),e.jsxs("div",{className:"bg-orange-900/20 border border-orange-500/30 rounded-xl p-4",children:[e.jsxs("h3",{className:"font-bold text-orange-400",children:["Step ",t+1,": ",s[t].title]}),e.jsx("p",{className:"text-gray-300 mt-1",children:s[t].description})]}),e.jsx("div",{className:"bg-black/30 rounded-2xl p-8 border border-white/10",children:e.jsxs("div",{className:"flex items-center justify-between gap-2",children:[e.jsxs("div",{className:`transition-all duration-500 ${s[t].highlight==="latent"?"scale-110":""}`,children:[e.jsxs("div",{className:`w-20 h-20 rounded-full flex flex-col items-center justify-center ${r?"bg-gradient-to-br from-purple-500 to-violet-700":"bg-gradient-to-br from-violet-500 to-purple-700"} ${s[t].highlight==="latent"?"ring-2 ring-white sample-bounce":""}`,children:[e.jsx("p",{className:"text-lg font-bold",children:"z"}),e.jsx("p",{className:"text-xs opacity-80",children:r?"~N(0,I)":"encoded"})]}),e.jsx("p",{className:`text-center text-sm mt-2 ${s[t].highlight==="latent"?"text-purple-300":"text-gray-500"}`,children:r?"Sampled":"Latent"}),e.jsx("p",{className:"text-center text-xs text-gray-500",children:"[batch, 20]"})]}),e.jsx(d,{className:"text-gray-600"}),e.jsx(m,{count:200,width:50,color:"bg-gradient-to-b from-orange-600 to-orange-800",label:"Hidden 1",sublabel:"ReLU",active:s[t].highlight==="hidden1"}),e.jsx(d,{className:"text-gray-600"}),e.jsx(m,{count:400,width:60,color:"bg-gradient-to-b from-orange-600 to-orange-800",label:"Hidden 2",sublabel:"ReLU",active:s[t].highlight==="hidden2"}),e.jsx(d,{className:"text-gray-600"}),e.jsx(m,{count:784,width:80,color:"bg-gradient-to-b from-red-600 to-red-800",label:"Output",sublabel:"Sigmoid",active:s[t].highlight==="output"}),e.jsx(d,{className:"text-gray-600"}),e.jsxs("div",{className:`transition-all duration-500 ${s[t].highlight==="image"?"scale-110":""}`,children:[e.jsx("div",{className:`w-24 h-24 rounded-xl bg-gradient-to-br from-pink-500 to-rose-600 flex items-center justify-center ${s[t].highlight==="image"?"ring-2 ring-white":""}`,children:e.jsx("div",{className:"grid grid-cols-4 gap-0.5",children:N.map((n,a)=>e.jsx("div",{className:`w-3 h-3 rounded-sm transition-all ${n?"bg-white/90":"bg-white/20"}`},a))})}),e.jsx("p",{className:`text-center text-sm mt-2 ${s[t].highlight==="image"?"text-pink-300":"text-gray-500"}`,children:r?"Generated":"Reconstructed"}),e.jsx("p",{className:"text-center text-xs text-gray-500",children:"28√ó28"})]})]})}),e.jsxs("div",{className:"bg-black/40 rounded-xl p-4 border border-white/10",children:[e.jsx("p",{className:"text-sm text-gray-400 mb-3",children:"PyTorch Decoder Implementation:"}),e.jsx("pre",{className:"text-sm overflow-x-auto",children:e.jsx("code",{className:"text-orange-300",children:`class Decoder(nn.Module):
    def __init__(self, latent_dim=20, hidden_dim=400, output_dim=784):
        super().__init__()
        self.fc1 = nn.Linear(latent_dim, hidden_dim // 2)
        self.fc2 = nn.Linear(hidden_dim // 2, hidden_dim)
        self.fc_out = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, z):
        h = F.relu(self.fc1(z))
        h = F.relu(self.fc2(h))
        # Sigmoid for pixel values in [0, 1]
        return torch.sigmoid(self.fc_out(h))

# Generation: sample from prior and decode
def generate(decoder, num_samples=10, latent_dim=20):
    z = torch.randn(num_samples, latent_dim)  # Sample z ~ N(0, I)
    with torch.no_grad():
        generated = decoder(z)
    return generated.view(-1, 1, 28, 28)  # Reshape to images`})})]}),e.jsxs("div",{className:"grid md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-orange-900/20 rounded-xl p-4 border border-orange-500/30",children:[e.jsx("h4",{className:"font-bold text-orange-300 mb-2",children:"Why Sigmoid Output?"}),e.jsx("p",{className:"text-sm text-gray-300",children:"For images normalized to [0,1], sigmoid constrains outputs to valid pixel values. This also works well with Binary Cross-Entropy loss for reconstruction."})]}),e.jsxs("div",{className:"bg-purple-900/20 rounded-xl p-4 border border-purple-500/30",children:[e.jsx("h4",{className:"font-bold text-purple-300 mb-2",children:"Decoder as Generator"}),e.jsx("p",{className:"text-sm text-gray-300",children:"After training, the decoder alone is a generative model! Sample z randomly, decode it, and you get novel samples from the learned data distribution."})]})]}),e.jsxs("div",{className:"bg-black/30 rounded-xl p-4 border border-white/10",children:[e.jsx("h4",{className:"font-bold mb-3",children:"üèóÔ∏è Decoder Architecture Variants"}),e.jsxs("div",{className:"grid md:grid-cols-3 gap-4",children:[e.jsxs("div",{className:"bg-white/5 rounded-lg p-3",children:[e.jsx("h5",{className:"font-medium text-orange-400",children:"MLP Decoder"}),e.jsx("p",{className:"text-xs text-gray-400 mt-1",children:"Fully connected layers. Simple but works for small images like MNIST."})]}),e.jsxs("div",{className:"bg-white/5 rounded-lg p-3",children:[e.jsx("h5",{className:"font-medium text-orange-400",children:"Transposed Conv (Deconv)"}),e.jsx("p",{className:"text-xs text-gray-400 mt-1",children:"ConvTranspose2d layers for upsampling. Better for larger images."})]}),e.jsxs("div",{className:"bg-white/5 rounded-lg p-3",children:[e.jsx("h5",{className:"font-medium text-orange-400",children:"Upsample + Conv"}),e.jsx("p",{className:"text-xs text-gray-400 mt-1",children:"Nearest/bilinear upsample followed by conv. Avoids checkerboard artifacts."})]})]})]})]})}export{L as default};
