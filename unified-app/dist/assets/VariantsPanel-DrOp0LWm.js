import{r as o,j as e,o as c,M as m,b as h,X as r,Z as p}from"./index-BmgLEcVh.js";import{C as t}from"./check-C1vjUz50.js";function g(){const[i,x]=o.useState("encoder-only"),d={"encoder-only":{name:"Encoder-Only",icon:h,color:"blue",examples:["BERT","RoBERTa","ALBERT","DistilBERT","ELECTRA"],useCase:"Understanding / Classification",description:"Bidirectional attention - each position can see all other positions. Great for understanding tasks.",tasks:["Text Classification","Named Entity Recognition","Question Answering","Sentiment Analysis"],attention:"Full bidirectional self-attention",training:"Masked Language Modeling (MLM)",diagram:{encoder:!0,decoder:!1}},"decoder-only":{name:"Decoder-Only",icon:m,color:"purple",examples:["GPT-1/2/3/4","LLaMA","Claude","PaLM","Mistral","Falcon"],useCase:"Generation / Completion",description:"Causal (left-to-right) attention only. Designed for autoregressive text generation.",tasks:["Text Generation","Chat/Dialogue","Code Generation","Creative Writing"],attention:"Causal self-attention (masked)",training:"Next Token Prediction",diagram:{encoder:!1,decoder:!0}},"encoder-decoder":{name:"Encoder-Decoder",icon:c,color:"green",examples:["T5","BART","mT5","FLAN-T5","mBART"],useCase:"Sequence-to-Sequence",description:"Full transformer as originally proposed. Best for tasks with distinct input and output sequences.",tasks:["Translation","Summarization","Text-to-Text","Data-to-Text"],attention:"Bidirectional (enc) + Causal (dec) + Cross",training:"Seq2Seq / Denoising",diagram:{encoder:!0,decoder:!0}}},s=d[i],n={blue:"bg-blue-500/20 border-blue-500/50 text-blue-400",purple:"bg-purple-500/20 border-purple-500/50 text-purple-400",green:"bg-green-500/20 border-green-500/50 text-green-400"};return e.jsx("div",{className:"p-6 min-h-screen",children:e.jsxs("div",{className:"max-w-6xl mx-auto",children:[e.jsxs("div",{className:"text-center mb-8",children:[e.jsxs("h2",{className:"text-3xl font-bold text-white mb-2",children:["Transformer Variants: ",e.jsx("span",{className:"gradient-text",children:"The Family Tree"})]}),e.jsx("p",{className:"text-slate-400",children:"Three architectural patterns that dominate modern NLP"})]}),e.jsx("div",{className:"flex justify-center gap-4 mb-8",children:Object.entries(d).map(([a,l])=>e.jsxs("button",{onClick:()=>x(a),className:`flex items-center gap-2 px-6 py-3 rounded-xl font-medium transition-all ${i===a?`${n[l.color]} border-2`:"bg-slate-700/50 text-slate-400 hover:bg-slate-700 border-2 border-transparent"}`,children:[e.jsx(l.icon,{size:20}),l.name]},a))}),e.jsxs("div",{className:"grid grid-cols-1 lg:grid-cols-2 gap-8",children:[e.jsxs("div",{className:"bg-slate-800/50 rounded-2xl p-6 border border-slate-700",children:[e.jsxs("h3",{className:"text-white font-bold mb-4 text-center",children:[s.name," Architecture"]}),e.jsxs("div",{className:"flex justify-center items-end gap-8 h-64",children:[e.jsxs("div",{className:"flex flex-col items-center",children:[s.diagram.encoder?e.jsxs("div",{className:"w-24 h-40 bg-gradient-to-t from-green-600 to-green-400 rounded-lg flex flex-col items-center justify-center p-2",children:[e.jsx("div",{className:"text-white font-bold text-sm",children:"ENCODER"}),e.jsx("div",{className:"text-white/70 text-xs mt-2 text-center",children:"Bidirectional Attention"})]}):e.jsxs("div",{className:"w-24 h-40 bg-slate-700/30 rounded-lg flex flex-col items-center justify-center p-2 border-2 border-dashed border-slate-600",children:[e.jsx(r,{className:"text-slate-500",size:32}),e.jsx("div",{className:"text-slate-500 text-xs mt-2",children:"Not Used"})]}),e.jsx("div",{className:"text-slate-400 text-xs mt-2",children:"Encoder"})]}),s.diagram.encoder&&s.diagram.decoder&&e.jsxs("div",{className:"flex flex-col items-center justify-center h-40",children:[e.jsx(c,{className:"text-yellow-400",size:32}),e.jsx("div",{className:"text-yellow-400 text-xs mt-1",children:"K, V"})]}),e.jsxs("div",{className:"flex flex-col items-center",children:[s.diagram.decoder?e.jsxs("div",{className:"w-24 h-48 bg-gradient-to-t from-purple-600 to-purple-400 rounded-lg flex flex-col items-center justify-center p-2",children:[e.jsx("div",{className:"text-white font-bold text-sm",children:"DECODER"}),e.jsx("div",{className:"text-white/70 text-xs mt-2 text-center",children:"Causal Attention"}),s.diagram.encoder&&e.jsx("div",{className:"text-yellow-300 text-xs mt-1 text-center",children:"+ Cross-Attn"})]}):e.jsxs("div",{className:"w-24 h-48 bg-slate-700/30 rounded-lg flex flex-col items-center justify-center p-2 border-2 border-dashed border-slate-600",children:[e.jsx(r,{className:"text-slate-500",size:32}),e.jsx("div",{className:"text-slate-500 text-xs mt-2",children:"Not Used"})]}),e.jsx("div",{className:"text-slate-400 text-xs mt-2",children:"Decoder"})]})]}),e.jsx("div",{className:"mt-6 p-4 bg-slate-700/30 rounded-lg",children:e.jsx("p",{className:"text-slate-300 text-sm",children:s.description})})]}),e.jsxs("div",{className:"space-y-4",children:[e.jsxs("div",{className:`rounded-xl p-4 border ${n[s.color]}`,children:[e.jsx("h4",{className:"font-bold mb-2",children:"Primary Use Case"}),e.jsx("p",{className:"text-white text-lg",children:s.useCase})]}),e.jsxs("div",{className:"bg-slate-800/50 rounded-xl p-4 border border-slate-700",children:[e.jsx("h4",{className:"text-white font-bold mb-2",children:"Attention Pattern"}),e.jsx("p",{className:"text-slate-300",children:s.attention})]}),e.jsxs("div",{className:"bg-slate-800/50 rounded-xl p-4 border border-slate-700",children:[e.jsx("h4",{className:"text-white font-bold mb-2",children:"Training Objective"}),e.jsx("p",{className:"text-slate-300",children:s.training})]}),e.jsxs("div",{className:"bg-slate-800/50 rounded-xl p-4 border border-slate-700",children:[e.jsx("h4",{className:"text-white font-bold mb-2",children:"Common Tasks"}),e.jsx("div",{className:"flex flex-wrap gap-2",children:s.tasks.map((a,l)=>e.jsx("span",{className:"bg-slate-700 px-3 py-1 rounded-full text-sm text-slate-300",children:a},l))})]}),e.jsxs("div",{className:"bg-slate-800/50 rounded-xl p-4 border border-slate-700",children:[e.jsx("h4",{className:"text-white font-bold mb-2",children:"Popular Models"}),e.jsx("div",{className:"flex flex-wrap gap-2",children:s.examples.map((a,l)=>e.jsx("span",{className:`px-3 py-1 rounded-full text-sm font-medium ${n[s.color]}`,children:a},l))})]})]})]}),e.jsxs("div",{className:"mt-8 bg-slate-800/50 rounded-2xl p-6 border border-slate-700",children:[e.jsx("h3",{className:"text-white font-bold mb-4",children:"üìä Quick Comparison"}),e.jsx("div",{className:"overflow-x-auto",children:e.jsxs("table",{className:"w-full text-sm",children:[e.jsx("thead",{children:e.jsxs("tr",{className:"border-b border-slate-700",children:[e.jsx("th",{className:"text-left text-slate-400 py-3 px-4",children:"Feature"}),e.jsx("th",{className:"text-center text-blue-400 py-3 px-4",children:"Encoder-Only"}),e.jsx("th",{className:"text-center text-purple-400 py-3 px-4",children:"Decoder-Only"}),e.jsx("th",{className:"text-center text-green-400 py-3 px-4",children:"Encoder-Decoder"})]})}),e.jsxs("tbody",{className:"text-slate-300",children:[e.jsxs("tr",{className:"border-b border-slate-700/50",children:[e.jsx("td",{className:"py-3 px-4 text-slate-400",children:"Bidirectional?"}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(r,{className:"inline text-red-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx("span",{className:"text-yellow-400",children:"Partial"})})]}),e.jsxs("tr",{className:"border-b border-slate-700/50",children:[e.jsx("td",{className:"py-3 px-4 text-slate-400",children:"Autoregressive?"}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(r,{className:"inline text-red-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})})]}),e.jsxs("tr",{className:"border-b border-slate-700/50",children:[e.jsx("td",{className:"py-3 px-4 text-slate-400",children:"Best for Generation?"}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(r,{className:"inline text-red-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})})]}),e.jsxs("tr",{className:"border-b border-slate-700/50",children:[e.jsx("td",{className:"py-3 px-4 text-slate-400",children:"Best for Understanding?"}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx("span",{className:"text-yellow-400",children:"OK"})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})})]}),e.jsxs("tr",{children:[e.jsx("td",{className:"py-3 px-4 text-slate-400",children:"Cross-Attention?"}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(r,{className:"inline text-red-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(r,{className:"inline text-red-400",size:18})}),e.jsx("td",{className:"py-3 px-4 text-center",children:e.jsx(t,{className:"inline text-green-400",size:18})})]})]})]})})]}),e.jsxs("div",{className:"mt-8 bg-gradient-to-r from-indigo-500/10 to-purple-500/10 rounded-2xl p-6 border border-indigo-500/30",children:[e.jsxs("h3",{className:"text-indigo-400 font-bold mb-4 flex items-center gap-2",children:[e.jsx(p,{size:20}),"Modern Trends (2023-2024)"]}),e.jsxs("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-4",children:[e.jsxs("div",{className:"bg-slate-800/50 p-4 rounded-lg",children:[e.jsx("h4",{className:"text-white font-medium mb-2",children:"ü¶ô Decoder-Only Dominance"}),e.jsx("p",{className:"text-slate-400 text-sm",children:"GPT, LLaMA, Mistral - decoder-only models dominate due to simplicity and scaling properties. They can be prompted to do encoder tasks too!"})]}),e.jsxs("div",{className:"bg-slate-800/50 p-4 rounded-lg",children:[e.jsx("h4",{className:"text-white font-medium mb-2",children:"üîÄ Mixture of Experts (MoE)"}),e.jsx("p",{className:"text-slate-400 text-sm",children:'Models like Mixtral use sparse MoE layers - only some "experts" activate per token. More parameters, same compute!'})]}),e.jsxs("div",{className:"bg-slate-800/50 p-4 rounded-lg",children:[e.jsx("h4",{className:"text-white font-medium mb-2",children:"üìè Longer Context"}),e.jsx("p",{className:"text-slate-400 text-sm",children:"Techniques like RoPE, ALiBi, and sparse attention enable 100K+ token contexts. Original transformer: only 512 tokens!"})]}),e.jsxs("div",{className:"bg-slate-800/50 p-4 rounded-lg",children:[e.jsx("h4",{className:"text-white font-medium mb-2",children:"üñºÔ∏è Multimodal"}),e.jsx("p",{className:"text-slate-400 text-sm",children:"GPT-4V, Gemini, LLaVA - transformers now process images, audio, and text together. Same architecture, different encoders!"})]})]})]})]})})}export{g as default};
