import{c as o,r as n,j as e,I as p,o as r,h,M as d,L as b}from"./index-BmgLEcVh.js";import{T as j}from"./type-BP-qhCPg.js";/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */const N=o("Music",[["path",{d:"M9 18V5l12-2v13",key:"1jmyc2"}],["circle",{cx:"6",cy:"18",r:"3",key:"fqmcym"}],["circle",{cx:"18",cy:"16",r:"3",key:"1hluhg"}]]);/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */const f=o("Video",[["path",{d:"m22 8-6 4 6 4V8Z",key:"50v9me"}],["rect",{width:"14",height:"12",x:"2",y:"6",rx:"2",ry:"2",key:"1rqjg6"}]]),v=[{id:"text",icon:j,label:"Text",color:"blue",examples:["Questions","Descriptions","Code"]},{id:"image",icon:p,label:"Vision",color:"green",examples:["Photos","Diagrams","Screenshots"]},{id:"audio",icon:N,label:"Audio",color:"purple",examples:["Speech","Music","Sounds"]},{id:"video",icon:f,label:"Video",color:"orange",examples:["Clips","Animations","Streams"]}],c=[{inputs:["image","text"],question:"What's in this image?",description:"Image captioning: Model sees an image and generates a text description",output:"A cat sitting on a windowsill looking outside"},{inputs:["image","text"],question:"How many apples are in the basket?",description:"Visual Question Answering (VQA): Combine vision + reasoning",output:"There are 7 red apples in the basket"},{inputs:["text"],question:"Generate an image of a sunset over mountains",description:"Text-to-Image: Understanding text to create visuals",output:"ðŸ–¼ï¸ [Generated Image]"},{inputs:["audio","text"],question:"Transcribe and summarize this meeting",description:"Audio understanding: Speech recognition + summarization",output:"Summary: Q3 results discussed, 15% growth..."}];function S(){const[l,m]=n.useState(0),[x,g]=n.useState(0);n.useEffect(()=>{const s=setInterval(()=>{g(t=>(t+1)%4)},1e3);return()=>clearInterval(s)},[]);const a=c[l];return e.jsx("div",{className:"p-8 h-full",children:e.jsxs("div",{className:"max-w-4xl mx-auto",children:[e.jsxs("div",{className:"text-center mb-8",children:[e.jsx("h2",{className:"text-3xl font-bold text-indigo-900 mb-4",children:"What are Multimodal LLMs?"}),e.jsxs("p",{className:"text-lg text-slate-700 leading-relaxed max-w-2xl mx-auto",children:["Multimodal LLMs can understand and generate content across ",e.jsx("strong",{children:"multiple types of data"})," - text, images, audio, and video - all in one unified model."]})]}),e.jsx("div",{className:"grid grid-cols-2 md:grid-cols-4 gap-4 mb-8",children:v.map((s,t)=>{const i=s.icon,u={blue:"bg-blue-50 border-blue-200 text-blue-600",green:"bg-green-50 border-green-200 text-green-600",purple:"bg-purple-50 border-purple-200 text-purple-600",orange:"bg-orange-50 border-orange-200 text-orange-600"};return e.jsxs("div",{className:`p-4 rounded-xl border-2 text-center transition-all duration-500 ${u[s.color]} ${x===t?"scale-110 shadow-lg":""}`,children:[e.jsx(i,{className:"mx-auto mb-2",size:32}),e.jsx("h3",{className:"font-bold",children:s.label}),e.jsx("div",{className:"text-xs mt-2 text-slate-600",children:s.examples.join(" â€¢ ")})]},s.id)})}),e.jsxs("div",{className:"bg-gradient-to-r from-indigo-50 to-purple-50 rounded-xl p-6 mb-8 border border-indigo-100",children:[e.jsx("h3",{className:"text-xl font-bold text-indigo-900 mb-4 text-center",children:"The Key Insight: Shared Representation Space"}),e.jsxs("div",{className:"flex items-center justify-center gap-4 flex-wrap",children:[e.jsxs("div",{className:"flex flex-col items-center",children:[e.jsx("div",{className:"text-3xl mb-1",children:"ðŸ–¼ï¸"}),e.jsx("span",{className:"text-sm",children:"Image"})]}),e.jsxs("div",{className:"flex flex-col items-center",children:[e.jsx("div",{className:"text-3xl mb-1",children:"ðŸ“"}),e.jsx("span",{className:"text-sm",children:"Text"})]}),e.jsxs("div",{className:"flex flex-col items-center",children:[e.jsx("div",{className:"text-3xl mb-1",children:"ðŸŽµ"}),e.jsx("span",{className:"text-sm",children:"Audio"})]}),e.jsx(r,{className:"text-indigo-400 mx-4",size:32}),e.jsx("div",{className:"bg-white rounded-xl p-4 shadow-md border",children:e.jsxs("div",{className:"text-center",children:[e.jsx(h,{className:"mx-auto text-indigo-600 mb-2",size:32}),e.jsx("div",{className:"font-bold text-indigo-900",children:"Unified"}),e.jsx("div",{className:"font-bold text-indigo-900",children:"Embedding Space"}),e.jsx("div",{className:"font-mono text-xs text-slate-500 mt-1",children:"[0.23, -0.45, ...]"})]})}),e.jsx(r,{className:"text-indigo-400 mx-4",size:32}),e.jsxs("div",{className:"flex flex-col items-center",children:[e.jsx(d,{className:"text-green-600 mb-1",size:32}),e.jsx("span",{className:"text-sm font-bold",children:"Understanding"})]})]}),e.jsxs("p",{className:"text-center text-slate-600 mt-4 text-sm",children:["Different modalities are encoded into the ",e.jsx("strong",{children:"same vector space"}),", allowing the model to reason across them."]})]}),e.jsxs("div",{className:"bg-slate-50 rounded-xl p-6 mb-8",children:[e.jsx("h3",{className:"text-xl font-bold text-slate-800 mb-4",children:"Example Tasks"}),e.jsx("div",{className:"flex flex-wrap gap-2 mb-4",children:c.map((s,t)=>e.jsxs("button",{onClick:()=>m(t),className:`px-4 py-2 rounded-lg font-medium transition-all ${l===t?"bg-indigo-600 text-white":"bg-white border hover:bg-slate-100"}`,children:[s.inputs.map(i=>i==="image"?"ðŸ–¼ï¸":i==="audio"?"ðŸŽµ":"ðŸ“").join("+")," ",s.question.slice(0,20),"..."]},t))}),e.jsxs("div",{className:"bg-white rounded-lg p-4 border",children:[e.jsxs("div",{className:"flex items-start gap-4 mb-4",children:[e.jsx("div",{className:"flex gap-2",children:a.inputs.map(s=>e.jsx("div",{className:`w-12 h-12 rounded-lg flex items-center justify-center text-2xl ${s==="image"?"bg-green-100":s==="audio"?"bg-purple-100":"bg-blue-100"}`,children:s==="image"?"ðŸ–¼ï¸":s==="audio"?"ðŸŽµ":"ðŸ“"},s))}),e.jsxs("div",{className:"flex-1",children:[e.jsx("div",{className:"text-sm text-slate-500 mb-1",children:"Input:"}),e.jsxs("div",{className:"font-medium text-slate-800",children:['"',a.question,'"']})]})]}),e.jsx("div",{className:"text-sm text-slate-600 bg-slate-50 p-3 rounded mb-4",children:a.description}),e.jsxs("div",{className:"flex items-start gap-4",children:[e.jsx("div",{className:"w-12 h-12 rounded-lg bg-indigo-100 flex items-center justify-center",children:e.jsx(d,{className:"text-indigo-600",size:24})}),e.jsxs("div",{className:"flex-1",children:[e.jsx("div",{className:"text-sm text-slate-500 mb-1",children:"Output:"}),e.jsx("div",{className:"font-medium text-green-700",children:a.output})]})]})]})]}),e.jsx("div",{className:"grid grid-cols-2 md:grid-cols-4 gap-3 mb-8",children:[{name:"GPT-4V",company:"OpenAI",capabilities:"Text + Vision"},{name:"Gemini",company:"Google",capabilities:"Text + Vision + Audio"},{name:"Claude 3",company:"Anthropic",capabilities:"Text + Vision"},{name:"LLaVA",company:"Open Source",capabilities:"Text + Vision"}].map(s=>e.jsxs("div",{className:"bg-white rounded-lg p-3 border text-center",children:[e.jsx("div",{className:"font-bold text-slate-800",children:s.name}),e.jsx("div",{className:"text-xs text-slate-500",children:s.company}),e.jsx("div",{className:"text-xs text-indigo-600 mt-1",children:s.capabilities})]},s.name))}),e.jsxs("div",{className:"bg-amber-50 p-4 rounded-xl border border-amber-200 flex items-start gap-3",children:[e.jsx(b,{className:"text-amber-600 flex-shrink-0 mt-1",size:24}),e.jsxs("div",{children:[e.jsx("h4",{className:"font-bold text-amber-900 mb-1",children:"Key Insight"}),e.jsxs("p",{className:"text-amber-800 text-sm",children:["The magic of multimodal LLMs is ",e.jsx("strong",{children:"alignment"}),' - training different encoders (vision, audio) to map their inputs into the same space as text. This allows the language model to "understand" images and sounds as if they were words.']})]})]})]})})}export{S as default};
